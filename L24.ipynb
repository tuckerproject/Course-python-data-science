{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L24.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2KCvjUTAfFhv","colab_type":"text"},"source":["We load data from fashion MNIST, where personal items of clothing to stand in for personal images and train a naive Bayes classifier to distinguish two classes in the “fashion MNIST” dataset, t-shirts and sneakers.\n","\n","`trainX`, `trainY`, `testX`, and `testY` are the full set of training and testing examples from the dataset, where `X` represents the instances and `Y` the labels."]},{"cell_type":"code","metadata":{"id":"oEUtVfHZWcH7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1590505860798,"user_tz":240,"elapsed":9743,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"42ac80ca-4230-4fd8-b41a-bf645c283065"},"source":["# Load fashion MNIST, split into training/testing\n","!pip install keras=='2.3.1'\n","from keras.datasets import fashion_mnist\n","((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 3us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 2s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ueAgwBikfHkb","colab_type":"text"},"source":["We import the Gaussian naive Bayes model we'll be using for training as well as numpy for additional functions used throughout the notebook.\n","\n","The instances are arranged as 28 by 28 grayscale images. For training the model, we `reshape` the data into flat vectors of size 784.\n","\n","To simplify training, we convert the grayscale images to black and white. For each image, in the training and testing set, we compute the `median` grayscale value and call everything below that value zero and everything about that value one."]},{"cell_type":"code","metadata":{"id":"_bXE0bhvWctR","colab_type":"code","colab":{}},"source":["# from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","import numpy as np\n","\n","# flatten data\n","trainX = np.reshape(trainX,(len(trainX),-1))\n","testX = np.reshape(testX,(len(testX),-1))\n","\n","# grayscale to B&W\n","testX = testX > np.reshape(np.median(testX,1),(-1,1))\n","trainX = trainX > np.reshape(np.median(trainX,1),(-1,1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rnq2SaPFfIW7","colab_type":"text"},"source":["The fashion MNIST dataset includes ten classes, but we’re onlyll just looking at using class 0, which are t-shirts, and class 7, which are sneakers. \n","\n","`testYpair`, `testXpair`, `trainYpair`, and `trainXpair` are subsets of the training and testing data where only the pair of target classes are retained.\n","\n","The dataset includes 12000 training examples and 2000 testing examples, evenly split across the two categories."]},{"cell_type":"code","metadata":{"id":"jpDIUrcTW7Wt","colab_type":"code","colab":{}},"source":["class0 = 0 # top\n","class1 = 7 # sneaker\n","testYpair = 0+np.compress(np.logical_or(testY == class0, testY == class1), testY)\n","testXpair = 0+np.compress(np.logical_or(testY == class0, testY == class1), testX, axis=0)\n","trainYpair = 0+np.compress(np.logical_or(trainY == class0, trainY == class1), trainY)\n","trainXpair = 0+np.compress(np.logical_or(trainY == class0, trainY == class1), trainX, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XAlHyG0piKfG","colab_type":"text"},"source":["Below we define the function `showpic` to display images in the data."]},{"cell_type":"code","metadata":{"id":"eiH6J-sfyf7l","colab_type":"code","colab":{}},"source":["import keras.preprocessing.image as img\n","\n","def showpic(arr):\n","  onec = np.reshape(arr,(28,28,1))\n","  onecbw = 255*np.concatenate((onec,onec,onec),2)\n","  display(img.array_to_img(onecbw,scale=False))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhhORwgMijh9","colab_type":"text"},"source":["Here we display 10 images from `trainXpair` with their corresponding `trainYpair` label."]},{"cell_type":"code","metadata":{"id":"IMGUclXOW-iy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1590440167263,"user_tz":240,"elapsed":7173,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"e83a6cfc-2a5c-4cbe-b3b6-a5a5efc7ec44"},"source":["for i in range(10):\n","  print(trainYpair[i])\n","  showpic(trainXpair[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAfElEQVR4nO2UOQ4AIAgExfj/L2NhYgiHEqSwYEuOYYNHazchoozIIBX4WSYCOESB+nEWuqcQmTg0LOpmWIklua9D8Vbc6WHesBJblqMn6KFZjl/FnYaczXcfbNQrDoBDY3S5H/30/XtUK9Muf0EL+jFUfXtfOi1oPlT9+iahmi0w7JiSqwAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474B38>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAXUlEQVR4nO2WQQoAIAgEs///2Q6BCLWhSZ12TmE62MFKGkZV50JEInFjH/WVB5C0ZwsiQGkFSin9JY1MFMopdZoe0wol6ZPjIyillNIv0si7f/NDsZr14phbPsczAAK4GzkQp8SyAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474860>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAdElEQVR4nO2UQQ7AIAgEl6b//zK99cTiAolNTOdoZFBQgDrunm8wJdLMQt273pHGkcQI4MojFUVfWkKVLqvRkZY4QFpqtyqd8Es3SktfSJUuSbIeUFMFVoFYOukSlQ75WqrPrY0nnQxTKhVhue88gL2t/CoPh/AeN+kiEOIAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474B38>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["7\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAdUlEQVR4nO2SSw7AIAgFwfT+V35d2FKCtkRk04RZieCIH6Ki+DcAAJiBzk6LF+xv+01hV8fMOrTr72xP9fD41vWitXMRNdOFrBeda9Q1V79j83omAGtLWDdeUeTKXFq6kfRD5Uvl9+wT/Ia+18T7G2SduCgeTq3KXN0ZoR+uAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474860>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAd0lEQVR4nO2V4QrAIAiEbez9X/n2IxhDTyNskGP3L9KvU8REHAEA4N3GAY1GByyCaBpyTOVTWRMaOmuTaoFTMVbWQJV+6PvQPsl2nqnuMBUfJQ9n1nu7bk8LQjObZb/yvWr2c/pVaPKnql5+Umd8/dyYAPpx2PELjx0qJcLnnFIAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474B38>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["7\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAYklEQVR4nO2RSQ6AMAwD7Yr/fxkOiCgCN0VQTnhO3TypEsAYc4P1YF/3nrUif9XlE5KyJABxkQPFd7I0PyPJ2MvKPWMBT6JnFuGd6AradCOK6b9hgRoRRj2RkQh+0lNjfssGZ+477A4nkxwAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474860>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAZElEQVR4nO3WyxIAEAgF0Pj/f86W3EKNhVFb7hmvmRBdqGKMMbOVLGoWD9jcUq9BEc6X6KkIU2Cl8bqP+vY+ZwfUeCVHJbfvdvugSmweBVzEo7efaKKJfo5GWoCKBsv/QyG9TTQvdCEn7ANifwAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474B38>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAArklEQVR4nM1TRw7DMAwLg/7/y+zBgeHGFCMPBOXJ0KBoDRwxSJYHAG+8QTtqps4BPPXd5OlMmdBHcoK0T4F359GK/UzkPCoQYx1CKUYypTTqfaldF0BKWVIa7dY5StSi1dG+BSkAt3e/kdK+pDSCWyl58n1M73Kk07dwLuY70i2oyq7vJ8dtkGJ4bEjq9ocYr+Q393TbmW4j3SMhGSY6PXQIclb/N6gj+NaLg1rEFywiYBUbe0tVAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474860>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAApklEQVR4nOWTSw7AIAhEwfT+V6aLNkZlACMmNems/AzPoVYiWyIiIvPrVQxrnIK3jLnamEfIONdWfUZLeXYHbjdp658sOkUYgoiKUzBPHMYFri6ka3VZGf0z/F3cfpiFmZ2PUxxfO61jC9eZrYzQDQ3ag1uYvzSY2vullvUTqPVXpaDWfWJo+Op9BS9qJzSpLBT2dGTST6HJq8fQvDZAdWenJtVv+gbGxlE0K83P6QAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474B38>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["7\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAfUlEQVR4nO2TSQ4AIQgE6fn/n5kDSbtlxIW5USejUJqOiCRJKFisU1UAXDcK9JJVaW2fnNoFz5ZobmSBI7Uiu981kkaqqt2jvnKc02TKzjMXezGKjnXFO27d6Ir03tKx9KW2pTYq41TcAHfmiJsSe3/JNOwbFWNokkkiIvIC01xE9ouu0n0AAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B44474860>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"8HlC_CkritzL","colab_type":"text"},"source":["We then train the Gaussian naive Bayes model `gnb` and get its predicitons for the test set, `predYpair`.  \n","\n","We then print the number of muislabeled points."]},{"cell_type":"code","metadata":{"id":"3p0PSmDFjORD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590440167434,"user_tz":240,"elapsed":7333,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"d80f529f-ba5d-4c01-8bcf-c5aae62b4ba4"},"source":["gnb = GaussianNB()\n","predYpair = gnb.fit(trainXpair, trainYpair).predict(testXpair)\n","print(\"Number of mislabeled points out of a total %d points : %d\"\n","       % (testXpair.shape[0], (testYpair != predYpair).sum()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of mislabeled points out of a total 2000 points : 3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C-qNGAOziyXU","colab_type":"text"},"source":["This code blocks shows how the predictions change when we randomly remove 1 example from the training data and train another model, `gnb2`, on that new training data `trainXpair2` and `trainYpair2`.  The number of mislabeled test datapoints when using `gnb2` are printed below."]},{"cell_type":"code","metadata":{"id":"26EDHIiZjKhM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590440167753,"user_tz":240,"elapsed":7642,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"f5277abe-15fc-4efc-b022-91ebcc1c4683"},"source":["# remove one at random\n","\n","remove = np.random.randint(0,len(trainXpair)+1)\n","removedX = trainXpair[remove]\n","removedY = trainYpair[remove]\n","trainXpair2 = np.concatenate((trainXpair[:remove],trainXpair[(remove+1):]))\n","trainYpair2 = np.concatenate((trainYpair[:remove],trainYpair[(remove+1):]))\n","gnb2 = GaussianNB()\n","predYpair2 = gnb2.fit(trainXpair2, trainYpair2).predict(testXpair)\n","print(\"Number of mislabeled points out of a total %d points : %d\"\n","       % (testXpair.shape[0], (testYpair != predYpair2).sum()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of mislabeled points out of a total 2000 points : 3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R9ruW_UojhN0","colab_type":"text"},"source":["Below we take the average of the images from each class `trainXpair2`. `example0` is the average of data belonging of the shoe class.  The average of the data belonging to the shirt class is `example1`."]},{"cell_type":"code","metadata":{"id":"SBh4YjYIY4fw","colab_type":"code","colab":{}},"source":["example0 = np.mean(np.compress(trainYpair2 == class0, trainXpair2, axis=0),axis=0)\n","example1 = np.mean(np.compress(trainYpair2 == class1, trainXpair2, axis=0),axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CkF6i5ajiFz","colab_type":"text"},"source":["This `binarysearch` function simulates a `query` image to estimate the image we have removed from the dataset used in training. It sumulates `query` by learning a weighted average of the images in `example1` and `example0` so that the `model` classifies the `query` as roughly 50 percent t-shirts and 50 percent sneakers.  The weighting parameter, `mid`, is updated based on the predictions of the `model`.  If the model predicts a probability is less than 0.5, we update `right` so that `mid` decreases, otherwise we updates `left` so that `mid` increases.  When `right` and `left` are close in value, we return our weighted image."]},{"cell_type":"code","metadata":{"id":"q9WIYRZDTNeI","colab_type":"code","colab":{}},"source":["# binary search\n","\n","def binarysearch(model):\n","  left = 0\n","  right = 1\n","\n","  while (right-left > 0.00000001):\n","    mid = (right+left)/2\n","    exampleMid = np.reshape((1-mid)*example0+mid*example1,(1,-1))\n","    if model.predict_proba(exampleMid)[0][0] < 0.5:\n","      right = mid\n","      \n","    else:\n","      left = mid\n","  query = np.reshape((1-mid)*example0+mid*example1,(1,-1))\n","  return(query)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fz4nDNc-rEFr","colab_type":"text"},"source":["Our `attack` on original model learns a reconstruction of the removed image `recon`.  Starting with `query` and synthetic image that the trained model classifies as roughly 50 percent t-shirts,we see how each of the two models classifies the test instance, the original model and model trained without the target data item.\n","\n","Then, for each column, we replace all values in a column with 1. We again see how the original model and the new model to classify this instance and note which one reacts more “strongly” to the change by changing its class prediction.\n","\n","The reconstruction of the image is exactly the pattern of which components cause more of a reaction in the original model or the retrained model.\n","\n","We display the reconstruction, `recon`, below."]},{"cell_type":"code","metadata":{"id":"Qy1BV45rUzsY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1590440245315,"user_tz":240,"elapsed":1642,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"875bd275-ef5d-43a3-ae53-265e0aab30f5"},"source":["# Let's say we know the label of the removed data point.\n","# Wouldn't it be the case that moving from vector v to v_{i=val} would make THAT\n","# label more likely i...\n","\n","# We train up two different NB models. Assume they differ in class0 by a single \n","# vector m.\n","# The models for class1 should be the same.\n","# Let's consider two inputs x and x' that differ only in dimension i.\n","# The old model should be M = sum_{v in class0} v / # instances in class0.\n","# The new model should be M' = (sum_{v in class0} v - m) / # instances in class0-1\n","# Roughly, we are looking at M.x, M'.x, M.x', M'.x'.\n","\n","# M'.x ~ (M-v).x\n","# => M.x - v.x\n","# So, M.x - M'.x ~ v.x\n","# So, (M.x - M'.x) - (M.x' - M'.x') ~ v_i\n","\n","\n","# hmmm. So, if example0[i] and example1[i] are the same, might as well choose \n","# that value. We won't see much evidence that will separate the two cases \n","# anyway.\n","# If example0[i] is bigger than example1[i], then putting a 1 at position i\n","# should make class 0 more likely. If the likelihood EHNANCEMENT is positive,\n","# then the missing vector probably has a 1 there, too.\n","\n","def attack(gnb, gnb2, example0, example1):\n","  recon = []\n","  query = binarysearch(gnb)\n","  z = np.reshape(query,(1,-1))\n","  z2 = np.reshape(query,(1,-1))\n","  for i in range(len(trainXpair[0])):\n","    e = np.copy(z)\n","    e[0][i] = 1.0\n","    pz = gnb.predict_proba(z)[0][1]\n","    pe_1 = gnb.predict_proba(e)[0][1]\n","    strength = pe_1*(pz-1) / (2 *pe_1*pz - pe_1 - pz)\n","\n","    e[0][i] = 0.0\n","    pe_0 = gnb.predict_proba(e)[0][1]\n","\n","    e2 = np.copy(z2)\n","    e2[0][i] = 1.0\n","    pz2 = gnb2.predict_proba(z2)[0][1]\n","    pe2_1 = gnb2.predict_proba(e2)[0][1]\n","    e2[0][i] = 0.0\n","    pe2_0 = gnb2.predict_proba(e2)[0][1]\n","    strength2 = pe2_1*(pz2-1) / (2 *pe2_1*pz2 - pe2_1 - pz2)\n","\n","    e2[0][i] = 0.0\n","    pe2_0 = gnb2.predict_proba(e)[0][1]\n","\n","    if abs(example0[i] - example1[i]) < 0.001: recon += [example0[i]]\n","    else:\n","      if strength > strength2:\n","        recon += [0]\n","      else:\n","        recon += [1]\n","  return(recon)\n","\n","recon = attack(gnb, gnb2, example0, example1)\n","\n","showpic(recon)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n","(1, 784)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA10lEQVR4nLWVURaFIAhExdP+1+ku6INCFATTnC/yxXXG1AfpFSKmPQEAFXkTJMW2oHteE3sk/em0ge6vJhOoyD6RcgFAV/gTBPERMaRoZeloxJ0B0WtPoK/NjogYx5dLKVfWMZs4vmOTERxw9HI9UYhIX8Ocn351+s2Ryzc1ClFPpGXl0kO6Uxe+jh1TR5xucgNUaLjzncXdchq666GmhVIK19hq1FKnNzfHfNLO/nP1TTaPZE5/5D8q66FNYgNduIylZPtvUMkJbsZJSjdy5Owbu2wRJPzebJ6J7+IeqvEAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7F4B443F12E8>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"iSKzTP7Ru9zp","colab_type":"text"},"source":["Below we show the image that was removed."]},{"cell_type":"code","metadata":{"id":"Q_2yVB4kafuj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":45},"executionInfo":{"status":"ok","timestamp":1590002391747,"user_tz":240,"elapsed":696,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"3af529b3-dd9f-43cf-e659-1684021d0dd9"},"source":["showpic(removedX)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAf0lEQVR4nO2TQQ6AMAgEWeP/v1wPNJRY3FJPxjAnqcuURBQpil/RWuNvNcBjsc6afWk6fTi5C4CIAAjv10PNeO51mAuNPmMBvR7eYqMRF6Eb8y5LEt0ol3NZA/d6Dpk+6DxdXtcbedSPuSHdGiHJ2NPMGiV5v0CPxulfKIpPcgHB0XfZdOvxkwAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7FD85C4AD278>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"W0VB7mtFvMQw","colab_type":"text"},"source":["Below is the image that we learned using `attack`."]},{"cell_type":"code","metadata":{"id":"Z2_u4sZLAKEW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":45},"executionInfo":{"status":"ok","timestamp":1590002387806,"user_tz":240,"elapsed":680,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"9eca0a49-7c66-4a47-9ccc-3bb6c969331e"},"source":["showpic(1-np.array(recon))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAyUlEQVR4nNWVXQ7DIAyD7aiH4P4HJX0IyvgbY20mdX4Car6akipUVQCqKiK4p5wzSQCHQUMkIjlnAOLzKPQLGiwL/GTgH6nU0v4nWBefqrph6/bNbYVdb/apqvpTAFyzzDrGbBCthz6fhuoWO9UeN9hiv3lq3RRJI0yOv8j17jWG8/HnXL5hza39guFCx3SbOJdguJY6+zXudxG2iHb8UgetUkqXuYePYvP+Uk9MOs8U2VZ9FNhbWDp1UItu+n5sCxT/R+9zjUDyBABGnyaDK4doAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7FD85C4AD390>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"FK2zz8sNvfUQ","colab_type":"text"},"source":["Now we'll use IBM's `diffprivlib` to train differentially private models."]},{"cell_type":"code","metadata":{"id":"5nrRpeNpsoxv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1590002410137,"user_tz":240,"elapsed":4513,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"e87b95ea-1a0f-4fe8-c914-7b939ad28eb8"},"source":["!pip install diffprivlib"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'differential-privacy-library' already exists and is not an empty directory.\n","Requirement already satisfied: diffprivlib in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.15.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.18.4)\n","Requirement already satisfied: setuptools>=39.0.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (46.3.0)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.22.2.post1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hp_xAB5-vnmH","colab_type":"text"},"source":["Below we import the differentially private version of Gaussian naive Bayes and train the model, `gnb`, on our original data.  We print the accuracy of the model below."]},{"cell_type":"code","metadata":{"id":"nU50G8ZoXeoW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1590002416577,"user_tz":240,"elapsed":2954,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"c643e475-f184-4421-f80b-e2b2aeb72508"},"source":["import diffprivlib.models as dpmodel\n","\n","gnb = dpmodel.GaussianNB()\n","predYpair = gnb.fit(trainXpair, trainYpair).predict(testXpair)\n","print(\"Number of mislabeled points out of a total %d points : %d\"\n","       % (testXpair.shape[0], (testYpair != predYpair).sum()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/diffprivlib/models/naive_bayes.py:93: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n","  \"privacy leakage, specify bounds for each dimension.\", PrivacyLeakWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of mislabeled points out of a total 2000 points : 57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C0VaAF6YwPJP","colab_type":"text"},"source":["Again we remove a single datapoint from the training set and train another differentially private naive Bayes model.  We report its performance below."]},{"cell_type":"code","metadata":{"id":"Ds9EXvK9e30i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1590002421863,"user_tz":240,"elapsed":2742,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"6c82ffb9-ce18-4301-94d8-08819f74393e"},"source":["# remove one\n","\n","# remove = np.random.randint(0,len(trainXpair)+1)\n","removedX = trainXpair[remove]\n","removedY = trainYpair[remove]\n","trainXpair2 = np.concatenate((trainXpair[:remove],trainXpair[(remove+1):]))\n","trainYpair2 = np.concatenate((trainYpair[:remove],trainYpair[(remove+1):]))\n","gnb2 = dpmodel.GaussianNB()\n","predYpair2 = gnb2.fit(trainXpair2, trainYpair2).predict(testXpair)\n","print(\"Number of mislabeled points out of a total %d points : %d\"\n","       % (testXpair.shape[0], (testYpair != predYpair2).sum()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/diffprivlib/models/naive_bayes.py:93: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n","  \"privacy leakage, specify bounds for each dimension.\", PrivacyLeakWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of mislabeled points out of a total 2000 points : 54\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KSJeLoltwcEG","colab_type":"text"},"source":["Next we try to rerun the `attack` we had showed earlier and display the `recon` image we have learned."]},{"cell_type":"code","metadata":{"id":"YsxjSkx8eixR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":45},"executionInfo":{"status":"ok","timestamp":1590002426944,"user_tz":240,"elapsed":1909,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"c77500f6-0ef2-490c-d0e6-93d8ef9d2a2b"},"source":["example0 = np.mean(np.compress(trainYpair2 == class0, trainXpair2, axis=0),axis=0)\n","example1 = np.mean(np.compress(trainYpair2 == class1, trainXpair2, axis=0),axis=0)\n","\n","recon = attack(gnb, gnb2, example0, example1)\n","\n","showpic(recon)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABM0lEQVR4nI1UQRLEIAiDzv7/m32Ge7DFmAR3PXQqICQRzJA1xoiIzFSXjdTgjw3qzqCF/uvLZWfceBdm0S25FJNBR3mxks2L24vciL84HnSY/5npiXdAVOiO73IhO4tCCf7UgUGplF2ZELmXSiTZ2JuDXBRWglo1DIozzRDRN7CqlIba8qpjWbaJmkQ6EVABIocKZCb3rXJUXJ1WFZnkJmjh7qqDv/qfkB6E+wf7U0lzESMjmZAjTNvsU3EcZxW6e3A3u/YW2qlqyEUZu6a779umG7AOULjI4XIsdo1nXcY+y52sz2Hpv7m9DuDrzOqV9yS95fSmXJQC+wMrURbSoZA9ScY75nimcHXwK4UeXLOvGDGRdhhVsj1nQulauw5F+guy1gx5O9TOfA9j1lHDH90q2C9eHQDACmpVKAAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=28x28 at 0x7FD85C502320>"]},"metadata":{"tags":[]}}]}]}
