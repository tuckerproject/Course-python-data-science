{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L12qs.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b5n8tihPasDN","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"bFSFDwOuJHBW","colab_type":"text"},"source":["In this notebook, we will build a recomendation system for academic papers. \n","\n","Below, we download the data we'll be using from GitHub. `vocab2.txt` contains the words in the tiles of the academic papers, and `cb.txt` contains the titles of the papers."]},{"cell_type":"code","metadata":{"id":"2tJcRhHcQYUy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1593641201791,"user_tz":240,"elapsed":3646,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"1ea628b7-d362-411e-de1e-b0a8f0805618"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/vocab2.txt\n","!wget https://github.com/mlittmancs/great_courses_ml/raw/master/cb.txt"],"execution_count":89,"outputs":[{"output_type":"stream","text":["--2020-07-01 22:06:38--  https://github.com/mlittmancs/great_courses_ml/raw/master/vocab2.txt\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab2.txt [following]\n","--2020-07-01 22:06:39--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab2.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 134845 (132K) [text/plain]\n","Saving to: ‘vocab2.txt.2’\n","\n","vocab2.txt.2        100%[===================>] 131.68K  --.-KB/s    in 0.02s   \n","\n","2020-07-01 22:06:39 (5.49 MB/s) - ‘vocab2.txt.2’ saved [134845/134845]\n","\n","--2020-07-01 22:06:40--  https://github.com/mlittmancs/great_courses_ml/raw/master/cb.txt\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/cb.txt [following]\n","--2020-07-01 22:06:40--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/cb.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 820122 (801K) [text/plain]\n","Saving to: ‘cb.txt.2’\n","\n","cb.txt.2            100%[===================>] 800.90K  --.-KB/s    in 0.05s   \n","\n","2020-07-01 22:06:40 (14.7 MB/s) - ‘cb.txt.2’ saved [820122/820122]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RwCUD_TANklv","colab_type":"text"},"source":["Here we write a few functions that will help us in processing the data:\n","\n","- `readvocab` creates a `vocab_dict` with a count of the number of times a word occurs in our paper titles\n","- `tokenize` turns each set of words in a title, `string`, into a count of the number of times each word in the title occurs\n","- `getdat`, which takes the titles and returns a list of titles with their word counts, `dat`, and a list of labels indicating if the user found the title interesting, `labs`\n","\n","We will use our function to process our data to get our vectorized titles, `dat`, and their labels `labs`"]},{"cell_type":"code","metadata":{"id":"V-Fu_cwlZGIU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593641209130,"user_tz":240,"elapsed":4610,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# read in the vocabulary file \n","def readvocab():\n","   # keep track of the number of words\n","    lexiconsize = 0\n","   # initialize an empty dictionary\n","    vocab_dict = {}\n","   # create a catch-all feature (vector component) for all unknown words\n","    vocab_dict[\"@unk\"] = lexiconsize\n","    lexiconsize += 1\n","   # read in the vocabulary file\n","    with open(\"vocab2.txt\", \"r\") as f:\n","        data = f.readlines()\n","   # Process the file a line at a time.\n","    for line in data:\n","        # The count is the first 3 characters\n","        count = int(line[0:4])\n","        # The word is the rest of the string\n","        token = line[5:-1]\n","       # Create a feature if it’s appeared at least twice\n","        if count > 1: \n","            vocab_dict[token] = lexiconsize\n","            lexiconsize += 1\n","    # squirrel away the total size for later reference\n","    vocab_dict[\"@size\"] = lexiconsize\n","    return(vocab_dict)\n","  \n","vocab_dict = readvocab()\n","\n","# Turn string str into a vector.\n","def tokenize(string, vocab_dict):\n","  # initially the vector is all zeros\n","  vec = [0 for i in range(vocab_dict[\"@size\"])]\n","  # for each word\n","  for t in string.split(\" \"):\n","   # if the word has a feature, add one to the corresponding feature\n","    if t in vocab_dict: vec[vocab_dict[t]] += 1\n","   # otherwise, count it as an unk\n","    else: vec[vocab_dict[\"@unk\"]] += 1\n","  return(vec)\n","\n","# read in labeled examples and turn the strings into vectors\n","def getdat(vocab_dict):\n","    with open(\"cb.txt\", \"r\") as f:\n","        data = f.readlines()\n","    dat = []\n","    labs = []\n","    for line in data:\n","        labs = labs + [int(line[0])]\n","        dat = dat + [tokenize(line[2:], vocab_dict)]\n","    return(dat, labs)\n","\n","(dat, labs) = getdat(vocab_dict)"],"execution_count":90,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53UHLTOiSdXl","colab_type":"text"},"source":["We define two additional helper functions to make our recommendations:\n","\n","- `playgame` makes `rounds` recommendations using `chooser` and is given a `score`.  For `alpha` days the selections are random.\n","\n","- `argmax` returns the index from `indices` associated wiht the item in the `vals` list with the highest value"]},{"cell_type":"code","metadata":{"id":"H2s0aTNrZGL0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593641215202,"user_tz":240,"elapsed":539,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["import random\n","from sklearn.naive_bayes import MultinomialNB\n","\n","def playgame(chooser, rounds, alpha):\n","  curitem = 0\n","  score = 0\n","  trainset = []\n","  trainlabs = []\n","  b = 5\n","  clf = MultinomialNB()\n","\n","  while curitem < rounds:\n","    chosenitem = chooser(curitem, b, trainset, trainlabs, alpha, clf)\n","    score = score + labs[chosenitem]\n","    trainset = trainset + [dat[chosenitem]]\n","    trainlabs = trainlabs + [labs[chosenitem]]\n","    curitem += b\n","  return(score)\n","\n","def argmax(indices, vals):\n"," best = max(vals)\n"," for i in range(len(indices)):\n","   if vals[i] == best: \n","     return(indices[i])"],"execution_count":91,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrscWdZXWNzd","colab_type":"text"},"source":["This function is our choosing function, `probachooser` and chooses between `b` options. `currentitem` is the initial item to consider.  `trainset` represents the results of previous selections. \n","\n","\n","If we have not yet made `alpha` selections, the selection is random. \n","\n","If we have made `alpha` selections in the past, we fit our `clf` Naive Bayes model using the traing data of academic papers by title, `trainset`, and training labels for if the academic papers were interesting, `trainlabs`.  After we fit our `clf` model, we use it to select the item most likely to be labeled as interesting."]},{"cell_type":"code","metadata":{"id":"dlCqy7KhZGP9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593641225221,"user_tz":240,"elapsed":702,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["def probachooser(curitem, b, trainset, trainlabs, alpha, clf):\n","  if len(trainset) == alpha:\n","    clf = clf.fit(trainset, trainlabs)\n","#comment?\n","  if len(trainset) < alpha:\n","    chosenitem = random.randint(curitem,curitem+b-1)\n","  else:\n","    yhat = clf.predict_proba(dat[curitem:(curitem+b)])\n","    chosenitem = argmax(range(curitem,curitem+b), [p for (c,p) in yhat])\n","  return(chosenitem)"],"execution_count":92,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zk6cY0iQdkqS","colab_type":"text"},"source":["We write our `probachooser` function so that `alpha` is now used as a smoothing parameter for our Naive Bayes model, ranging between 0 and 1.  We train our Naive Bayes classifier on every data element using our smoothing parameter in our Naive Bayes model, `alpha`. The `chosenitem` returned is just the one our classifier thinks is most likely to be interesting.\n","\n","We also will rewrite our `playgame` function to accomodate the changes we made in `probachooser`.\n","\n","Given these changes, we will plot how our score changes as we vary `alpha` from 0.00005 to 1."]},{"cell_type":"code","metadata":{"id":"tFWoqjQcZGV0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593641252717,"user_tz":240,"elapsed":743,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["def probachooser(curitem, b, trainset, trainlabs, alpha):\n","  if len(trainset) == 0:\n","    chosenitem = random.randint(curitem,curitem+b-1)\n","  else:\n","    clf = MultinomialNB(alpha=alpha)\n","    clf = clf.fit(trainset, trainlabs)\t\n","    yhat = clf.predict_proba(dat[curitem:(curitem+b)])\n","    chosenitem = argmax(range(curitem,curitem+b), [p for (c,p) in yhat])\n","  return(chosenitem)\n","\n","def playgame(chooser, rounds, alpha):\n","  curitem = 0\n","  score = 0\n","  trainset = []\n","  trainlabs = []\n","  b = 5\n","\n","  while curitem < rounds:\n","    chosenitem = chooser(curitem, b, trainset, trainlabs, alpha)\n","    score = score + labs[chosenitem]\n","    trainset = trainset + [dat[chosenitem]]\n","    trainlabs = trainlabs + [labs[chosenitem]]\n","    curitem += b\n","  return(score)"],"execution_count":93,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZbGc7xobBXT","colab_type":"text"},"source":["A helper function that is given a bunch of probabilities and picks a position. Here's where we do the Thompson sampling idea. Each article is actually either interesting or not. We use our probability estimate to decide which is which by flipping a weighted coin. Then, we choose one of the interesting articles uniformly at random. If none are interesting, we choose an uninteresting article uniformly at random."]},{"cell_type":"code","metadata":{"id":"0J_Hg2eKwepR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593629547796,"user_tz":240,"elapsed":820,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# return one of the \"1\" positions at random, or a \"0\" position at random otherwise.\n","def pickone(v):\n","  pick = np.random.randint(0,len(v))\n","  c = 0\n","  for i in range(len(v)):\n","    if v[i] == 1:\n","      c += 1\n","      if np.random.binomial(1,1.0/c): pick = i\n","  return(pick)"],"execution_count":83,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8-ZdO3RbahO","colab_type":"text"},"source":["Now, for the Thompson-sampling-based chooser. It follows the naive Bayes chooser from the lecture, except instead of choosing the most interesting article, it chooses uses the Thompson-sampling idea to choose an interesting article."]},{"cell_type":"code","metadata":{"id":"lgbYVvYCtwgU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593629551158,"user_tz":240,"elapsed":672,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["def thompsonchooser(curitem, b, trainset, trainlabs, alpha):\n","  if len(trainset) == 0:\n","    chosenitem = random.randint(curitem,curitem+b-1)\n","  else:\n","    clf = MultinomialNB(alpha=alpha)\n","    clf = clf.fit(trainset, trainlabs)\t\n","    # yhat is a probability\n","    yhat = clf.predict_proba(dat[curitem:(curitem+b)])\n","    pick = pickone([np.random.binomial(1,pr[0]) for pr in yhat])+curitem\n","#    chosenitem = argmax(range(curitem,curitem+b), [p for (c,p) in yhat])\n","#    print(pick)\n","    chosenitem = pick\n","  return(chosenitem)"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQP1T23dbrLK","colab_type":"text"},"source":["Here's the range of results for a set of alphas"]},{"cell_type":"code","metadata":{"id":"llRrDYR0y3Sh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593642108872,"user_tz":240,"elapsed":572715,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["alphas = [.05, .5, 5, 50, 500, 5000]\n","rep = 10\n","ress = []\n","mins = []\n","maxs = []\n","for alpha in alphas:\n","  total = 0\n","  res = []\n","  for i in range(rep):\n","    res += [playgame(thompsonchooser, 1000, alpha)]\n","  ress += [sum(res)/rep]\n","  mins += [min(res)]\n","  maxs += [max(res)]"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEaX41yY-ake","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1593642108875,"user_tz":240,"elapsed":566254,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"e6256c9e-d8b6-4a0a-e8b7-6293d9db769d"},"source":["plt.scatter(alphas, ress)\n","plt.plot(alphas, ress)\n","plt.fill_between(alphas, mins, maxs, alpha=0.6)   \n","plt.show()"],"execution_count":95,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}
