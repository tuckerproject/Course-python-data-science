{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L15qs.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XcV9bp_VhCIP","colab_type":"text"},"source":["This notebook trains an image classification model and makes gradual improvements, debugging the model, to improve performance.  **GPUs are encouraged.** In colab, one can add a GPU by clicking the `Runtime` menu and selecting `Change runtime type`. Selecting `GPU` as the hardware accelerator will allow for the usage of a GPU.\n","\n","Below we download and `unzip` the tiny ImageNet dataset.\n","\n","Tiny ImageNet is a dataset based on ImageNet with 100,000 images. The dataset consists of 200 categories instead of Imagenet’s full 1,000 categories. Each image is a 64x64 pixel color image, which is about one-twelfth the size of those in Imagenet. Imagenet’s images are 224x224 pixels. There are 500 images in each category instead of Imagenet's roughly 1000 images per category."]},{"cell_type":"code","metadata":{"id":"wk0s93zj_-ID","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593775447161,"user_tz":240,"elapsed":31342,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"fea2a79f-0ed9-4316-b84a-b5e5f7703598"},"source":["!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","!unzip -q tiny-imagenet-200.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-07-03 11:23:36--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n","Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248100043 (237M) [application/zip]\n","Saving to: ‘tiny-imagenet-200.zip’\n","\n","tiny-imagenet-200.z 100%[===================>] 236.61M  11.7MB/s    in 21s     \n","\n","2020-07-03 11:23:57 (11.4 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r8UPlT7XhXsz","colab_type":"text"},"source":["We’ll import some code for image processing. We’ll use `keras` for building our algorithm and `numpy` for working with vectors. We’ll also use a function from `sklearn`, the scikit learn library, for splitting up training and testing vectors.\n","\n","From the 200 categories in the set, we select a list of 36 categories that correspond to animals, `cats_0`. The list includes lions, boa constrictors, and king penguins.\n","\n","We also select a list of 14 categories from tiny imagenet that correspond to bugs, `cats_1`. The list includes roaches, grasshoppers, scorpions, tarantulas, and dragonflies. "]},{"cell_type":"code","metadata":{"id":"63fNdjPFAACr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1593775451181,"user_tz":240,"elapsed":33133,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"8c2a4b1d-c6b6-42a1-9449-772633a2e6a4"},"source":["!pip install keras=='2.3.1'\n","from PIL import Image\n","from keras.preprocessing import image\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import random\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","cats_0 = ['n01443537','n01629819','n01641577','n01644900','n01698640','n01742172',\n","          'n01855672','n01882714','n02002724','n02056570','n02058221','n02074367',\n","          'n02085620','n02094433','n02099601','n02099712','n02106662','n02113799',\n","          'n02123045','n02123394','n02124075','n02125311','n02129165','n02132136',\n","          'n02364673','n02395406','n02403003','n02410509','n02415577','n02423022',\n","          'n02437312','n02480495','n02481823','n02486410','n02504458','n02509815']\n","cats_1 = ['n01770393','n01774384','n01774750','n01784675','n02165456','n02190166',\n","          'n02206856','n02226429','n02231487','n02233338','n02236044','n02268443',\n","          'n02279972','n02281406']"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gdt-rlrnjfpj","colab_type":"text"},"source":["The `read_cats` subroutine reads the images for the categories `cats` it is given and it associates their vectors with the label `lab`. Initially, the lists of vectors, `vecs`, and labels, `labs`, are empty. We also pass in the desired training and testing set sizes, `train_size` and `test_size`.\n","\n","\n","\n","We loop through each category, `c`, and image, `i`. For each category and image pair, we construct a filename into the “tiny” dataset. Specifically, the directory that stores the images is called “tiny-imagenet-200/tiny”. Then, there’s a subdirectory for each of the tiny imagenet categories, which contains a subdirectory called “images”. Within that directory, there’s 500 JPEG files, each named with the tiny imagenet category and a number.\n","\n","We retrieve the image and store it in “img”.\n","From the image object, we extract an array and flatten it out into a vector. Then, we reshape it to 64x64 x 3 colors.\n","We string together all the collected images and labels into lists, one list called “vecs”, the other called “labs”.\n","Once the lists are constructed, we turn the list of vectors into a numpy array.\n","We split up this array and the labels with the desired train/test sizes and return the result."]},{"cell_type":"code","metadata":{"id":"J_pmTe_rAAFn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593775451182,"user_tz":240,"elapsed":29016,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# Redefine read_cats to preprocess inputs\n","def read_cats(cats, lab, train_size, test_size):\n","  vecs = []\n","  labs = []\n","  for c in cats:\n","    for i in range(500):\n","      img = image.load_img(\"tiny-imagenet-200/train/\"+c+\"/images/\"+c+\"_\"+str(i)+\".JPEG\")\n","      img_arr = image.img_to_array(img)\n","      img_arr = preprocess_input(img_arr)\n","      img_arr = img_arr.flatten()\n","      img_arr = img_arr / 255. - 1\n","      img_arr = img_arr.reshape(64,64,3)\n","      vecs += [img_arr]\n","      labs += [lab]\n","  vecs = np.asarray(vecs)\n","  return(train_test_split(vecs,labs, train_size=train_size,test_size=test_size))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xN1AOvD9oBYH","colab_type":"text"},"source":["For both `cats_1` and `cats_0`, we use 10 percent of the available data for training and 20 percent for testing. Combining the data from each category will give us our training data, `X_train` and `y_train`, and our test data, `X_test` and `y_test`."]},{"cell_type":"code","metadata":{"id":"s2BjLZxWAAOb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593775463088,"user_tz":240,"elapsed":38903,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["X0_train, X0_test, y0_train, y0_test = read_cats(cats_0, 0, .1, .2)\n","X1_train, X1_test, y1_train, y1_test = read_cats(cats_1, 1, .1, .2)\n","X_train = np.concatenate((X0_train, X1_train))\n","X_test = np.concatenate((X0_test, X1_test))\n","y_train = np.concatenate((y0_train, y1_train))\n","y_test = np.concatenate((y0_test, y1_test))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DHEe8jMxoB78","colab_type":"text"},"source":["`build_network` builds a VGG-16 model. It consists of a series of 14 convolutional layers, `Conv2D`, interspersed with max pooling layers, `MaxPooling2D`. After these layers, it includes 3 fully connected, `Dense`, layers ending with the output layer.\n","\n","In the code to build and return the untrained neural network, the main change is in the very first layer and the very last layer. VGG-16 is designed to recognize imagenet images of size 224x224. The “tiny” images in this set are only 64x64. So `input_shape` is different.\n","\n","The output shape is also different. In the Imagenet challenge, the learners have to pick out an image from 1000 categories. Here, we only have two --- animal and bug. So, we use a single output unit with `sigmoid` activation. A sigmoid unit is one that outputs a number near 1 if the input sums to a positive number and near zero if the input sums to a negative number, with a smooth transition between them around zero. Thus, the outputs look like probabilities. It is trained to produce a number close to 1 for bugs and close to 0 for animals."]},{"cell_type":"code","metadata":{"id":"uRZHJmk-AATB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593775463089,"user_tz":240,"elapsed":35693,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["def build_network():\n","  import keras\n","  from keras.models import Sequential\n","  from keras.layers import Dense, Activation, Dropout, Flatten\n","  from keras.layers import Conv2D\n","  from keras.layers import MaxPooling2D\n","  input_shape = (64, 64, 3)\n","  #Instantiate an empty model\n","  model = Sequential()\n","  model.add(Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'))\n","  model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","  model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","  model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","  model.add(Flatten())\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(Dense(1, activation='sigmoid'))\n","  return(model)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gm7Qbe6l1XN7","colab_type":"text"},"source":["Now we dramatically increase the size of the training set to 10,000 examples, 5,000 of each class."]},{"cell_type":"code","metadata":{"id":"LnKVhy-p7XWq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593775474503,"user_tz":240,"elapsed":43245,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# running again with maximum training data\n","X0_train, X0_test, y0_train, y0_test = read_cats(cats_0, 0, 5000, 500)\n","X1_train, X1_test, y1_train, y1_test = read_cats(cats_1, 1, 5000, 500)\n","X_train = np.concatenate((X0_train, X1_train))\n","X_test = np.concatenate((X0_test, X1_test))\n","y_train = np.concatenate((y0_train, y1_train))\n","y_test = np.concatenate((y0_test, y1_test))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7bEm2zx1g1C","colab_type":"text"},"source":["We build and compile our model again using `SGD`."]},{"cell_type":"code","metadata":{"id":"HoLXWN6TN3La","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593781700865,"user_tz":240,"elapsed":6265885,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"85a0b374-d0de-41b2-ed46-cf00f7e4cc43"},"source":["from keras import optimizers\n","\n","for alpha in (0.001, 0.005, 0.01, 0.05, 0.01, 0.5):\n","  solver = optimizers.SGD(lr=alpha)\n","  model = build_network()\n","  model.compile(loss='mean_squared_error', optimizer=solver, metrics=['accuracy'])\n","  model.fit(X_train,y_train,epochs=100)\n","  print(model.evaluate(X_test,y_test))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","10000/10000 [==============================] - 17s 2ms/step - loss: 0.2500 - accuracy: 0.4971\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5013\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5017\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5215\n","Epoch 5/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5136\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5058\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5361\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5291\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5130\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5308\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5173\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5192\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5435\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5503\n","Epoch 15/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5393\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5268\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5651\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5461\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5559\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5738\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5480\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5671\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5597\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5312\n","Epoch 25/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5706\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5821\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5762\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5572\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5531\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5706\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5813\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5407\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5666\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5389\n","Epoch 35/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5684\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5745\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5553\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6024\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5755\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5530\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5607\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5798\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5637\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5699\n","Epoch 45/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5995\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5992\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6056\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5859\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6000\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5948\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5985\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5786\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5970\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5992\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5780\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5568\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5923\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5797\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6042\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6014\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5952\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5963\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5879\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6112\n","Epoch 65/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6079\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6111\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5906\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6049\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6046\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6135\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6116\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6114\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6088\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6051\n","Epoch 75/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6118\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6076\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6082\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6144\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6149\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6149\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6055\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.6111\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5873\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6224\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5759\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6125\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6052\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6162\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5703\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6081\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6239\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6207\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6247\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6213\n","Epoch 95/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6145\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6258\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6216\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6240\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6051\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.6213\n","1000/1000 [==============================] - 1s 504us/step\n","[0.24980871772766114, 0.6140000224113464]\n","Epoch 1/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2500 - accuracy: 0.4994\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5083\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5111\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5086\n","Epoch 5/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5215\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5182\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5191\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5126\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5089\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5226\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5462\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5580\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5611\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5310\n","Epoch 15/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5562\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5620\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5472\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2497 - accuracy: 0.5825\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2497 - accuracy: 0.5974\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2497 - accuracy: 0.5665\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2496 - accuracy: 0.5760\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2495 - accuracy: 0.6013\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2495 - accuracy: 0.6177\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2494 - accuracy: 0.6010\n","Epoch 25/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2493 - accuracy: 0.6199\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2491 - accuracy: 0.6051\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2490 - accuracy: 0.6181\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2487 - accuracy: 0.6088\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2485 - accuracy: 0.6137\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2482 - accuracy: 0.6066\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2477 - accuracy: 0.6152\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2472 - accuracy: 0.6120\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2464 - accuracy: 0.6122\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2455 - accuracy: 0.6100\n","Epoch 35/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2442 - accuracy: 0.6067\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2423 - accuracy: 0.6074\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2405 - accuracy: 0.5981\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2377 - accuracy: 0.6015\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2361 - accuracy: 0.5983\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2321 - accuracy: 0.6055\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2312 - accuracy: 0.6082\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2272 - accuracy: 0.6183\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2260 - accuracy: 0.6261\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2232 - accuracy: 0.6307\n","Epoch 45/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2220 - accuracy: 0.6341\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2184 - accuracy: 0.6418\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2141 - accuracy: 0.6610\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2071 - accuracy: 0.6737\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2024 - accuracy: 0.6910\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1949 - accuracy: 0.7071\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1911 - accuracy: 0.7122\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1875 - accuracy: 0.7197\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1848 - accuracy: 0.7245\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1817 - accuracy: 0.7300\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1803 - accuracy: 0.7351\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1784 - accuracy: 0.7358\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1766 - accuracy: 0.7379\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1734 - accuracy: 0.7420\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1733 - accuracy: 0.7491\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1719 - accuracy: 0.7505\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1700 - accuracy: 0.7508\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1682 - accuracy: 0.7565\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1678 - accuracy: 0.7557\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1676 - accuracy: 0.7524\n","Epoch 65/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1657 - accuracy: 0.7576\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1654 - accuracy: 0.7580\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1643 - accuracy: 0.7625\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1633 - accuracy: 0.7631\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1633 - accuracy: 0.7600\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1610 - accuracy: 0.7635\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1596 - accuracy: 0.7686\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1599 - accuracy: 0.7677\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1589 - accuracy: 0.7701\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1589 - accuracy: 0.7737\n","Epoch 75/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1588 - accuracy: 0.7694\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1575 - accuracy: 0.7715\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1573 - accuracy: 0.7729\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1565 - accuracy: 0.7724\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1554 - accuracy: 0.7765\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1552 - accuracy: 0.7741\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1532 - accuracy: 0.7779\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1552 - accuracy: 0.7728\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1520 - accuracy: 0.7785\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1536 - accuracy: 0.7777\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1524 - accuracy: 0.7763\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1505 - accuracy: 0.7820\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1510 - accuracy: 0.7785\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1512 - accuracy: 0.7819\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1501 - accuracy: 0.7825\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1486 - accuracy: 0.7845\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1491 - accuracy: 0.7830\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1474 - accuracy: 0.7867\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1475 - accuracy: 0.7846\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1478 - accuracy: 0.7865\n","Epoch 95/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1464 - accuracy: 0.7872\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1467 - accuracy: 0.7862\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1458 - accuracy: 0.7917\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1455 - accuracy: 0.7919\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1448 - accuracy: 0.7936\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1440 - accuracy: 0.7923\n","1000/1000 [==============================] - 0s 402us/step\n","[0.13160006469488145, 0.8040000200271606]\n","Epoch 1/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2500 - accuracy: 0.4980\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5029\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5120\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5069\n","Epoch 5/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5129\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5128\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5366\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5220\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2497 - accuracy: 0.5544\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2496 - accuracy: 0.5585\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2494 - accuracy: 0.5656\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2492 - accuracy: 0.5874\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2488 - accuracy: 0.6034\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2483 - accuracy: 0.6012\n","Epoch 15/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2473 - accuracy: 0.5929\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2456 - accuracy: 0.5921\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2434 - accuracy: 0.5812\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2407 - accuracy: 0.5825\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2355 - accuracy: 0.5950\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2312 - accuracy: 0.6014\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2284 - accuracy: 0.6130\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2252 - accuracy: 0.6161\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2220 - accuracy: 0.6298\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2172 - accuracy: 0.6546\n","Epoch 25/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2073 - accuracy: 0.6755\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1951 - accuracy: 0.7045\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1881 - accuracy: 0.7164\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1824 - accuracy: 0.7309\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1802 - accuracy: 0.7366\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1781 - accuracy: 0.7382\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1748 - accuracy: 0.7435\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1713 - accuracy: 0.7501\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1710 - accuracy: 0.7480\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1685 - accuracy: 0.7538\n","Epoch 35/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1669 - accuracy: 0.7593\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1656 - accuracy: 0.7554\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1648 - accuracy: 0.7583\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1626 - accuracy: 0.7597\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1626 - accuracy: 0.7652\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1605 - accuracy: 0.7690\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1584 - accuracy: 0.7686\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1589 - accuracy: 0.7682\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1565 - accuracy: 0.7723\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1558 - accuracy: 0.7730\n","Epoch 45/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1554 - accuracy: 0.7747\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1538 - accuracy: 0.7784\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1523 - accuracy: 0.7768\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1526 - accuracy: 0.7770\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1514 - accuracy: 0.7806\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1508 - accuracy: 0.7807\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1500 - accuracy: 0.7836\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1494 - accuracy: 0.7843\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1482 - accuracy: 0.7835\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1490 - accuracy: 0.7849\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1468 - accuracy: 0.7848\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1444 - accuracy: 0.7905\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1443 - accuracy: 0.7943\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1443 - accuracy: 0.7917\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1429 - accuracy: 0.7924\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1431 - accuracy: 0.7934\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1419 - accuracy: 0.7931\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1413 - accuracy: 0.7966\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1400 - accuracy: 0.7985\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1383 - accuracy: 0.8026\n","Epoch 65/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1381 - accuracy: 0.8033\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1375 - accuracy: 0.8010\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1356 - accuracy: 0.8091\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1356 - accuracy: 0.8050\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1361 - accuracy: 0.8063\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1345 - accuracy: 0.8090\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1325 - accuracy: 0.8130\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1321 - accuracy: 0.8104\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1303 - accuracy: 0.8150\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1294 - accuracy: 0.8156\n","Epoch 75/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1284 - accuracy: 0.8147\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1284 - accuracy: 0.8157\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1278 - accuracy: 0.8208\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1253 - accuracy: 0.8223\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1254 - accuracy: 0.8243\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1237 - accuracy: 0.8257\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1220 - accuracy: 0.8299\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1218 - accuracy: 0.8295\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1203 - accuracy: 0.8305\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1197 - accuracy: 0.8298\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1157 - accuracy: 0.8390\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1156 - accuracy: 0.8373\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1141 - accuracy: 0.8399\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1131 - accuracy: 0.8429\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1120 - accuracy: 0.8475\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1112 - accuracy: 0.8474\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1086 - accuracy: 0.8521\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1081 - accuracy: 0.8498\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1065 - accuracy: 0.8569\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1038 - accuracy: 0.8585\n","Epoch 95/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1049 - accuracy: 0.8554\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1009 - accuracy: 0.8624\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1005 - accuracy: 0.8638\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0956 - accuracy: 0.8729\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0953 - accuracy: 0.8730\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0938 - accuracy: 0.8749\n","1000/1000 [==============================] - 0s 403us/step\n","[0.13417078280448913, 0.8100000023841858]\n","Epoch 1/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2500 - accuracy: 0.5047\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5137\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2489 - accuracy: 0.5414\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2478 - accuracy: 0.5452\n","Epoch 5/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2422 - accuracy: 0.5785\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2323 - accuracy: 0.6105\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2107 - accuracy: 0.6783\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1907 - accuracy: 0.7180\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1839 - accuracy: 0.7300\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1787 - accuracy: 0.7390\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1733 - accuracy: 0.7404\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1694 - accuracy: 0.7517\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1682 - accuracy: 0.7524\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1666 - accuracy: 0.7506\n","Epoch 15/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.1633 - accuracy: 0.7604\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1627 - accuracy: 0.7597\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1600 - accuracy: 0.7621\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1565 - accuracy: 0.7730\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1560 - accuracy: 0.7693\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1557 - accuracy: 0.7710\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1509 - accuracy: 0.7795\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1489 - accuracy: 0.7820\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1447 - accuracy: 0.7874\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1454 - accuracy: 0.7870\n","Epoch 25/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1406 - accuracy: 0.7962\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1396 - accuracy: 0.7959\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1364 - accuracy: 0.8043\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1338 - accuracy: 0.8126\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1327 - accuracy: 0.8120\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1270 - accuracy: 0.8167\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1289 - accuracy: 0.8183\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1221 - accuracy: 0.8312\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1196 - accuracy: 0.8318\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1167 - accuracy: 0.8371\n","Epoch 35/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1106 - accuracy: 0.8470\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1084 - accuracy: 0.8519\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1051 - accuracy: 0.8561\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0992 - accuracy: 0.8657\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0950 - accuracy: 0.8711\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0923 - accuracy: 0.8759\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0858 - accuracy: 0.8854\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0805 - accuracy: 0.8947\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0764 - accuracy: 0.8994\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0707 - accuracy: 0.9075\n","Epoch 45/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.0651 - accuracy: 0.9165\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0583 - accuracy: 0.9261\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0548 - accuracy: 0.9317\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0507 - accuracy: 0.9365\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0493 - accuracy: 0.9378\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0420 - accuracy: 0.9484\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0366 - accuracy: 0.9557\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0403 - accuracy: 0.9501\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0325 - accuracy: 0.9606\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0314 - accuracy: 0.9619\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0295 - accuracy: 0.9647\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0273 - accuracy: 0.9682\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0265 - accuracy: 0.9683\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0230 - accuracy: 0.9726\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0229 - accuracy: 0.9721\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0261 - accuracy: 0.9683\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0183 - accuracy: 0.9780\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0251 - accuracy: 0.9694\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0146 - accuracy: 0.9829\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0153 - accuracy: 0.9824\n","Epoch 65/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0138 - accuracy: 0.9840\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0153 - accuracy: 0.9820\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0147 - accuracy: 0.9827\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0198 - accuracy: 0.9760\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0108 - accuracy: 0.9876\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0160 - accuracy: 0.9803\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0122 - accuracy: 0.9863\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0057 - accuracy: 0.9941\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.9926\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0079 - accuracy: 0.9911\n","Epoch 75/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.0141 - accuracy: 0.9831\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0130 - accuracy: 0.9853\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0074 - accuracy: 0.9921\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0046 - accuracy: 0.9955\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.9955\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0053 - accuracy: 0.9945\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0080 - accuracy: 0.9907\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0100 - accuracy: 0.9889\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0099 - accuracy: 0.9882\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0154 - accuracy: 0.9809\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0102 - accuracy: 0.9881\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0139 - accuracy: 0.9828\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0069 - accuracy: 0.9928\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.9913\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0065 - accuracy: 0.9931\n","Epoch 95/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0108 - accuracy: 0.9878\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0083 - accuracy: 0.9909\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0090 - accuracy: 0.9897\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0084 - accuracy: 0.9905\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0093 - accuracy: 0.9891\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0062 - accuracy: 0.9935\n","1000/1000 [==============================] - 0s 404us/step\n","[0.18436628967523574, 0.7879999876022339]\n","Epoch 1/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2500 - accuracy: 0.5043\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5213\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2499 - accuracy: 0.5179\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2498 - accuracy: 0.5366\n","Epoch 5/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2497 - accuracy: 0.5557\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2496 - accuracy: 0.5779\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2494 - accuracy: 0.5787\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2492 - accuracy: 0.6023\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2488 - accuracy: 0.5959\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2483 - accuracy: 0.5975\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2475 - accuracy: 0.6047\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2464 - accuracy: 0.6002\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2449 - accuracy: 0.5952\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2423 - accuracy: 0.5966\n","Epoch 15/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2381 - accuracy: 0.5966\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2353 - accuracy: 0.5966\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2305 - accuracy: 0.6084\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2286 - accuracy: 0.6132\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2265 - accuracy: 0.6172\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2243 - accuracy: 0.6219\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2214 - accuracy: 0.6319\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2167 - accuracy: 0.6482\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2088 - accuracy: 0.6727\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1990 - accuracy: 0.6999\n","Epoch 25/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1895 - accuracy: 0.7172\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1836 - accuracy: 0.7273\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1804 - accuracy: 0.7324\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1778 - accuracy: 0.7379\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1738 - accuracy: 0.7433\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1732 - accuracy: 0.7451\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1696 - accuracy: 0.7521\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1700 - accuracy: 0.7520\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1697 - accuracy: 0.7509\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1634 - accuracy: 0.7627\n","Epoch 35/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.1642 - accuracy: 0.7592\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1635 - accuracy: 0.7662\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1610 - accuracy: 0.7638\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1595 - accuracy: 0.7679\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1598 - accuracy: 0.7687\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1574 - accuracy: 0.7741\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1581 - accuracy: 0.7672\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1558 - accuracy: 0.7731\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1542 - accuracy: 0.7735\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1531 - accuracy: 0.7767\n","Epoch 45/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1530 - accuracy: 0.7786\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1520 - accuracy: 0.7792\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1518 - accuracy: 0.7770\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1511 - accuracy: 0.7795\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1493 - accuracy: 0.7807\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1499 - accuracy: 0.7815\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1483 - accuracy: 0.7878\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1470 - accuracy: 0.7855\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1474 - accuracy: 0.7869\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1459 - accuracy: 0.7860\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1457 - accuracy: 0.7888\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1448 - accuracy: 0.7900\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1434 - accuracy: 0.7947\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1429 - accuracy: 0.7914\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1415 - accuracy: 0.7959\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1415 - accuracy: 0.7944\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1398 - accuracy: 0.7956\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1389 - accuracy: 0.8003\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1390 - accuracy: 0.8007\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1388 - accuracy: 0.8012\n","Epoch 65/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.1357 - accuracy: 0.8044\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1367 - accuracy: 0.8019\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1340 - accuracy: 0.8100\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1362 - accuracy: 0.8014\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1333 - accuracy: 0.8087\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1326 - accuracy: 0.8123\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1315 - accuracy: 0.8144\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1307 - accuracy: 0.8129\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1297 - accuracy: 0.8157\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1290 - accuracy: 0.8146\n","Epoch 75/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1272 - accuracy: 0.8215\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1270 - accuracy: 0.8196\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1257 - accuracy: 0.8232\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1237 - accuracy: 0.8256\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1235 - accuracy: 0.8253\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1238 - accuracy: 0.8232\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1245 - accuracy: 0.8245\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1195 - accuracy: 0.8358\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1195 - accuracy: 0.8318\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1175 - accuracy: 0.8372\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1182 - accuracy: 0.8368\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1159 - accuracy: 0.8387\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1142 - accuracy: 0.8405\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1134 - accuracy: 0.8432\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1113 - accuracy: 0.8477\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1125 - accuracy: 0.8452\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1089 - accuracy: 0.8494\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1070 - accuracy: 0.8536\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1063 - accuracy: 0.8564\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1070 - accuracy: 0.8540\n","Epoch 95/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.1044 - accuracy: 0.8562\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1019 - accuracy: 0.8611\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.1009 - accuracy: 0.8627\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0994 - accuracy: 0.8643\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0973 - accuracy: 0.8708\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.0957 - accuracy: 0.8725\n","1000/1000 [==============================] - 0s 412us/step\n","[0.11242975783348083, 0.8460000157356262]\n","Epoch 1/100\n","10000/10000 [==============================] - 11s 1ms/step - loss: 0.2504 - accuracy: 0.5012\n","Epoch 2/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5016\n","Epoch 3/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4992\n","Epoch 4/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5030\n","Epoch 5/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5018\n","Epoch 6/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2505 - accuracy: 0.5015\n","Epoch 7/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5011\n","Epoch 8/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5041\n","Epoch 9/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4910\n","Epoch 10/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4978\n","Epoch 11/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4922\n","Epoch 12/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5000\n","Epoch 13/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5040\n","Epoch 14/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5010\n","Epoch 15/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4998\n","Epoch 16/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5070\n","Epoch 17/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4946\n","Epoch 18/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4918\n","Epoch 19/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5002\n","Epoch 20/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5008\n","Epoch 21/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5046\n","Epoch 22/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4936\n","Epoch 23/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5072\n","Epoch 24/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5018\n","Epoch 25/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4974\n","Epoch 26/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5006\n","Epoch 27/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4936\n","Epoch 28/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5018\n","Epoch 29/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5008\n","Epoch 30/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5036\n","Epoch 31/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5016\n","Epoch 32/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4942\n","Epoch 33/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4962\n","Epoch 34/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4998\n","Epoch 35/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5030\n","Epoch 36/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4992\n","Epoch 37/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4952\n","Epoch 38/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5045\n","Epoch 39/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4914\n","Epoch 40/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5042\n","Epoch 41/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4910\n","Epoch 42/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5044\n","Epoch 43/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5058\n","Epoch 44/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4984\n","Epoch 45/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4994\n","Epoch 46/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4954\n","Epoch 47/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5056\n","Epoch 48/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4932\n","Epoch 49/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5004\n","Epoch 50/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4966\n","Epoch 51/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5008\n","Epoch 52/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5044\n","Epoch 53/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4974\n","Epoch 54/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4962\n","Epoch 55/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4967\n","Epoch 56/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5028\n","Epoch 57/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5048\n","Epoch 58/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4962\n","Epoch 59/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4994\n","Epoch 60/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4862\n","Epoch 61/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5042\n","Epoch 62/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4972\n","Epoch 63/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5096\n","Epoch 64/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5028\n","Epoch 65/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4960\n","Epoch 66/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4978\n","Epoch 67/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4976\n","Epoch 68/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4958\n","Epoch 69/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4966\n","Epoch 70/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4948\n","Epoch 71/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2500 - accuracy: 0.5068\n","Epoch 72/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5034\n","Epoch 73/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5073\n","Epoch 74/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5030\n","Epoch 75/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4940\n","Epoch 76/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4972\n","Epoch 77/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4887\n","Epoch 78/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4992\n","Epoch 79/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5007\n","Epoch 80/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4943\n","Epoch 81/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4968\n","Epoch 82/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5100\n","Epoch 83/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.4876\n","Epoch 84/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4972\n","Epoch 85/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5020\n","Epoch 86/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5062\n","Epoch 87/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4986\n","Epoch 88/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4921\n","Epoch 89/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5039\n","Epoch 90/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2501 - accuracy: 0.5094\n","Epoch 91/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.5041\n","Epoch 92/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5003\n","Epoch 93/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5044\n","Epoch 94/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.4928\n","Epoch 95/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5034\n","Epoch 96/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2504 - accuracy: 0.5000\n","Epoch 97/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2497 - accuracy: 0.5222\n","Epoch 98/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2503 - accuracy: 0.5021\n","Epoch 99/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.4996\n","Epoch 100/100\n","10000/10000 [==============================] - 10s 1ms/step - loss: 0.2502 - accuracy: 0.5045\n","1000/1000 [==============================] - 0s 400us/step\n","[0.25117362308502195, 0.5]\n"],"name":"stdout"}]}]}
