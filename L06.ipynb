{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L06.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1-H4o3Mtf8I1","colab_type":"text"},"source":["In this noteobook, we will build a spam detector using two different models, a decision tree and a naive Bayes model. A naive Bayes classifier calculates the probability of a sequence of words belonging to a class as proprotional to the product of the probability of each item in a sequence given the class.\n","\n","Below we import the libraries we'll be using.\n"]},{"cell_type":"code","metadata":{"id":"ysfO6y4TygzU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595338560977,"user_tz":240,"elapsed":1071,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["from sklearn import tree\n","import graphviz \n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import confusion_matrix"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-flSIqbs4us","colab_type":"text"},"source":["Next we'll write a function to process the data into a dictionary of words and their number of occurances, `word_dict`, and a count of the number of words total, `lexiconsize`"]},{"cell_type":"code","metadata":{"id":"lwlVeKj9GLFx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595338563196,"user_tz":240,"elapsed":1381,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# read in the vocabulary file \n","def readvocab(vocab_path=\"vocab.txt\"):\n","   # keep track of the number of words\n","    lexiconsize = 0\n","   # initialize an empty dictionary\n","    word_dict = {}\n","   # create a feature for unknown words\n","    word_dict[\"@unk\"] = lexiconsize\n","    lexiconsize += 1\n","   # read in the vocabular file\n","    with open(vocab_path, \"r\") as f:\n","        data = f.readlines()\n","   # Process the file a line at a time.\n","    for line in data:\n","        # The count is the first 3 characters\n","        count = int(line[0:4])\n","        # The word is the rest of the string\n","        token = line[5:-1]\n","       # Create a feature if it’s appeared at least twice\n","        if count > 1: \n","            word_dict[token] = lexiconsize\n","            lexiconsize += 1\n","    # squirrel away the total size for later reference\n","    word_dict[\"@size\"] = lexiconsize\n","    return(word_dict)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M49cH5GGxTuG","colab_type":"text"},"source":["We will download the vocabulary data from GitHub, `vocab.txt`\n"]},{"cell_type":"code","metadata":{"id":"-TZ7Eft7CoRS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1595338568342,"user_tz":240,"elapsed":4113,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"29add4bd-8304-49bb-c7b3-f1fbdb79fad7"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/vocab.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["--2020-07-21 13:36:05--  https://github.com/mlittmancs/great_courses_ml/raw/master/vocab.txt\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab.txt [following]\n","--2020-07-21 13:36:06--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 83233 (81K) [text/plain]\n","Saving to: ‘vocab.txt’\n","\n","vocab.txt           100%[===================>]  81.28K  --.-KB/s    in 0.03s   \n","\n","2020-07-21 13:36:07 (2.77 MB/s) - ‘vocab.txt’ saved [83233/83233]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fL_XRUDS34IL","colab_type":"text"},"source":["Next, we write a `tokenize` function to turn each word into a list of the length of the number words.  Every item in the list is a count of the number of times a given word occurs in the list."]},{"cell_type":"code","metadata":{"id":"kg0eeOYEbKBP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595338568343,"user_tz":240,"elapsed":1745,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# Turn string str into a vector.\n","def tokenize(email_string, word_dict):\n","  # initially the vector is all zeros\n","  vec = [0 for i in range(word_dict[\"@size\"])]\n","  # for each word\n","  for t in email_string.split(\" \"):\n","   # if the word has a feature, add one to the corresponding feature\n","    if t in word_dict: vec[word_dict[t]] += 1\n","   # otherwise, count it as an unk\n","    else: vec[word_dict[\"@unk\"]] += 1\n","  return(vec)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wF_Qo8nEJijp","colab_type":"text"},"source":["From here, we write a `getdat` function to convert the file we downloaded into two lists:\n","\n","- `dat`: a list of lists of tokenized words\n","- `labs`: a list of labels associated with the email being spam or not spam"]},{"cell_type":"code","metadata":{"id":"821K7VKScgx5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595338574785,"user_tz":240,"elapsed":739,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# read in labeled examples and turn the strings into vectors\n","def getdat(filename, word_dict):\n","    with open(filename, \"r\") as f:\n","        data = f.readlines()\n","    dat = []\n","    labs = []\n","    for line in data:\n","        labs = labs + [int(line[0])]\n","        dat = dat + [tokenize(line[2:], word_dict)]\n","    return(dat, labs)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YcrtGdGMcqEg","colab_type":"text"},"source":["Now we'll download the train and test data from GitHub"]},{"cell_type":"code","metadata":{"id":"qpS1CVviDFIq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1595338584758,"user_tz":240,"elapsed":6744,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"d97ca426-5802-42a5-99a9-dc778d0b94e2"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-test.csv\n","!wget https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-train.csv"],"execution_count":16,"outputs":[{"output_type":"stream","text":["--2020-07-21 13:36:18--  https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-test.csv\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-test.csv [following]\n","--2020-07-21 13:36:19--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-test.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 166047 (162K) [text/plain]\n","Saving to: ‘spam-test.csv’\n","\n","spam-test.csv       100%[===================>] 162.16K  --.-KB/s    in 0.04s   \n","\n","2020-07-21 13:36:20 (3.70 MB/s) - ‘spam-test.csv’ saved [166047/166047]\n","\n","--2020-07-21 13:36:21--  https://github.com/mlittmancs/great_courses_ml/raw/master/data/spam-train.csv\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-train.csv [following]\n","--2020-07-21 13:36:22--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/data/spam-train.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 289027 (282K) [text/plain]\n","Saving to: ‘spam-train.csv’\n","\n","spam-train.csv      100%[===================>] 282.25K  --.-KB/s    in 0.05s   \n","\n","2020-07-21 13:36:24 (5.23 MB/s) - ‘spam-train.csv’ saved [289027/289027]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZPPYYmSxdTk_","colab_type":"text"},"source":["With these train and test datasets, we'll build create the data and labels we will use to train and use to test our naive Bayes model."]},{"cell_type":"code","metadata":{"id":"kIXOxbdFDpK4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595338588507,"user_tz":240,"elapsed":1619,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["word_dict = readvocab()\n","traindat, trainlabs = getdat(\"spam-train.csv\", word_dict)\n","testdat, testlabs = getdat(\"spam-test.csv\", word_dict)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_kNVQA_LhdE6","colab_type":"text"},"source":["With the training and testing data, we can fit a decision tree with 6 decision rules and print out the accuracy on the test data"]},{"cell_type":"code","metadata":{"id":"qX25q8kgdqS3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595338591018,"user_tz":240,"elapsed":2613,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"74344d91-efd7-4b73-f29a-b8d904eec2fe"},"source":["clf = tree.DecisionTreeClassifier(max_leaf_nodes = 6)\t\n","clf = clf.fit(traindat, trainlabs)\t\n","\n","yhat = clf.predict(testdat)\n","\n","sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9415"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"bLpCR7GXipHG","colab_type":"text"},"source":["We now will create a list of the words in our wordlist and use it to print the decision tree we have learned"]},{"cell_type":"code","metadata":{"id":"YIA3MiRfeCGx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":518},"executionInfo":{"status":"ok","timestamp":1595338591363,"user_tz":240,"elapsed":804,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"da7fabd7-1700-4697-da23-80fbe4c4e160"},"source":["wordlist = list(word_dict.keys())[:-1]\n","dot_data = tree.export_graphviz(clf, feature_names=wordlist,\n","                      filled=True, rounded=True) \n","graph = graphviz.Source(dot_data)\t\n","graph\t"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<graphviz.files.Source at 0x7fa81a176438>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"661pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 661.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 657,-369 657,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#e99457\" stroke=\"#000000\" d=\"M443,-365C443,-365 327,-365 327,-365 321,-365 315,-359 315,-353 315,-353 315,-309 315,-309 315,-303 321,-297 327,-297 327,-297 443,-297 443,-297 449,-297 455,-303 455,-309 455,-309 455,-353 455,-353 455,-359 449,-365 443,-365\"/>\n<text text-anchor=\"middle\" x=\"385\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">call &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"385\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.231</text>\n<text text-anchor=\"middle\" x=\"385\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3572</text>\n<text text-anchor=\"middle\" x=\"385\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [3096, 476]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e78c4b\" stroke=\"#000000\" d=\"M366,-261C366,-261 250,-261 250,-261 244,-261 238,-255 238,-249 238,-249 238,-205 238,-205 238,-199 244,-193 250,-193 250,-193 366,-193 366,-193 372,-193 378,-199 378,-205 378,-205 378,-249 378,-249 378,-255 372,-261 366,-261\"/>\n<text text-anchor=\"middle\" x=\"308\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">txt &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"308\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.152</text>\n<text text-anchor=\"middle\" x=\"308\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3208</text>\n<text text-anchor=\"middle\" x=\"308\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2943, 265]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M359.7873,-296.9465C353.2727,-288.1475 346.1795,-278.5672 339.3918,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.0327,-267.0843 333.2693,-261.13 336.4069,-271.2496 342.0327,-267.0843\"/>\n<text text-anchor=\"middle\" x=\"329.5809\" y=\"-282.1564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node7\" class=\"node\">\n<title>2</title>\n<path fill=\"#c9e4f8\" stroke=\"#000000\" d=\"M516,-261C516,-261 408,-261 408,-261 402,-261 396,-255 396,-249 396,-249 396,-205 396,-205 396,-199 402,-193 408,-193 408,-193 516,-193 516,-193 522,-193 528,-199 528,-205 528,-205 528,-249 528,-249 528,-255 522,-261 516,-261\"/>\n<text text-anchor=\"middle\" x=\"462\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">i &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"462\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.487</text>\n<text text-anchor=\"middle\" x=\"462\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 364</text>\n<text text-anchor=\"middle\" x=\"462\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [153, 211]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M410.2127,-296.9465C416.7273,-288.1475 423.8205,-278.5672 430.6082,-269.3993\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"433.5931,-271.2496 436.7307,-261.13 427.9673,-267.0843 433.5931,-271.2496\"/>\n<text text-anchor=\"middle\" x=\"440.4191\" y=\"-282.1564\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node3\" class=\"node\">\n<title>3</title>\n<path fill=\"#e78945\" stroke=\"#000000\" d=\"M229,-157C229,-157 113,-157 113,-157 107,-157 101,-151 101,-145 101,-145 101,-101 101,-101 101,-95 107,-89 113,-89 113,-89 229,-89 229,-89 235,-89 241,-95 241,-101 241,-101 241,-145 241,-145 241,-151 235,-157 229,-157\"/>\n<text text-anchor=\"middle\" x=\"171\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">www &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"171\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.109</text>\n<text text-anchor=\"middle\" x=\"171\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3120</text>\n<text text-anchor=\"middle\" x=\"171\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2939, 181]</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M263.1411,-192.9465C250.7222,-183.519 237.1217,-173.1946 224.2739,-163.4415\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.041,-160.3887 215.9597,-157.13 221.8085,-165.9642 226.041,-160.3887\"/>\n</g>\n<!-- 4 -->\n<g id=\"node6\" class=\"node\">\n<title>4</title>\n<path fill=\"#42a2e6\" stroke=\"#000000\" d=\"M354.5,-149.5C354.5,-149.5 271.5,-149.5 271.5,-149.5 265.5,-149.5 259.5,-143.5 259.5,-137.5 259.5,-137.5 259.5,-108.5 259.5,-108.5 259.5,-102.5 265.5,-96.5 271.5,-96.5 271.5,-96.5 354.5,-96.5 354.5,-96.5 360.5,-96.5 366.5,-102.5 366.5,-108.5 366.5,-108.5 366.5,-137.5 366.5,-137.5 366.5,-143.5 360.5,-149.5 354.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"313\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.087</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 88</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 84]</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M309.6372,-192.9465C310.1509,-182.2621 310.7199,-170.4254 311.2416,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.7396,-159.6987 311.7239,-149.5422 307.7477,-159.3625 314.7396,-159.6987\"/>\n</g>\n<!-- 7 -->\n<g id=\"node4\" class=\"node\">\n<title>7</title>\n<path fill=\"#e68743\" stroke=\"#000000\" d=\"M128,-53C128,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 128,0 128,0 134,0 140,-6 140,-12 140,-12 140,-41 140,-41 140,-47 134,-53 128,-53\"/>\n<text text-anchor=\"middle\" x=\"70\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.089</text>\n<text text-anchor=\"middle\" x=\"70\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3081</text>\n<text text-anchor=\"middle\" x=\"70\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2938, 143]</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge3\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M135.3912,-88.9777C125.6155,-79.6376 115.0223,-69.5163 105.266,-60.1947\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.644,-57.6261 97.9958,-53.2485 102.8083,-62.6873 107.644,-57.6261\"/>\n</g>\n<!-- 8 -->\n<g id=\"node5\" class=\"node\">\n<title>8</title>\n<path fill=\"#3ea0e6\" stroke=\"#000000\" d=\"M253.5,-53C253.5,-53 170.5,-53 170.5,-53 164.5,-53 158.5,-47 158.5,-41 158.5,-41 158.5,-12 158.5,-12 158.5,-6 164.5,0 170.5,0 170.5,0 253.5,0 253.5,0 259.5,0 265.5,-6 265.5,-12 265.5,-12 265.5,-41 265.5,-41 265.5,-47 259.5,-53 253.5,-53\"/>\n<text text-anchor=\"middle\" x=\"212\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.05</text>\n<text text-anchor=\"middle\" x=\"212\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39</text>\n<text text-anchor=\"middle\" x=\"212\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 38]</text>\n</g>\n<!-- 3&#45;&gt;8 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M185.4551,-88.9777C189.0733,-80.4617 192.9674,-71.2963 196.6283,-62.6798\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.9462,-63.8209 200.6354,-53.2485 193.5036,-61.0836 199.9462,-63.8209\"/>\n</g>\n<!-- 5 -->\n<g id=\"node8\" class=\"node\">\n<title>5</title>\n<path fill=\"#6db7ec\" stroke=\"#000000\" d=\"M507,-157C507,-157 407,-157 407,-157 401,-157 395,-151 395,-145 395,-145 395,-101 395,-101 395,-95 401,-89 407,-89 407,-89 507,-89 507,-89 513,-89 519,-95 519,-101 519,-101 519,-145 519,-145 519,-151 513,-157 507,-157\"/>\n<text text-anchor=\"middle\" x=\"457\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">me &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"457\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.329</text>\n<text text-anchor=\"middle\" x=\"457\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 255</text>\n<text text-anchor=\"middle\" x=\"457\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [53, 202]</text>\n</g>\n<!-- 2&#45;&gt;5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>2&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M460.3628,-192.9465C459.97,-184.776 459.5448,-175.9318 459.1332,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.6171,-166.9504 458.6409,-157.13 455.6252,-167.2866 462.6171,-166.9504\"/>\n</g>\n<!-- 6 -->\n<g id=\"node11\" class=\"node\">\n<title>6</title>\n<path fill=\"#e78c4b\" stroke=\"#000000\" d=\"M641,-149.5C641,-149.5 549,-149.5 549,-149.5 543,-149.5 537,-143.5 537,-137.5 537,-137.5 537,-108.5 537,-108.5 537,-102.5 543,-96.5 549,-96.5 549,-96.5 641,-96.5 641,-96.5 647,-96.5 653,-102.5 653,-108.5 653,-108.5 653,-137.5 653,-137.5 653,-143.5 647,-149.5 641,-149.5\"/>\n<text text-anchor=\"middle\" x=\"595\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.152</text>\n<text text-anchor=\"middle\" x=\"595\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 109</text>\n<text text-anchor=\"middle\" x=\"595\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [100, 9]</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge10\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M505.5492,-192.9465C520.7625,-181.0504 537.8023,-167.726 552.8957,-155.9237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"555.3351,-158.4592 561.0567,-149.5422 551.0231,-152.9449 555.3351,-158.4592\"/>\n</g>\n<!-- 9 -->\n<g id=\"node9\" class=\"node\">\n<title>9</title>\n<path fill=\"#4ea7e8\" stroke=\"#000000\" d=\"M467,-53C467,-53 367,-53 367,-53 361,-53 355,-47 355,-41 355,-41 355,-12 355,-12 355,-6 361,0 367,0 367,0 467,0 467,0 473,0 479,-6 479,-12 479,-12 479,-41 479,-41 479,-47 473,-53 467,-53\"/>\n<text text-anchor=\"middle\" x=\"417\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.171</text>\n<text text-anchor=\"middle\" x=\"417\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 222</text>\n<text text-anchor=\"middle\" x=\"417\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [21, 201]</text>\n</g>\n<!-- 5&#45;&gt;9 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M442.8975,-88.9777C439.3676,-80.4617 435.5684,-71.2963 431.9968,-62.6798\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"435.1499,-61.1461 428.0875,-53.2485 428.6834,-63.8265 435.1499,-61.1461\"/>\n</g>\n<!-- 10 -->\n<g id=\"node10\" class=\"node\">\n<title>10</title>\n<path fill=\"#e6853f\" stroke=\"#000000\" d=\"M592.5,-53C592.5,-53 509.5,-53 509.5,-53 503.5,-53 497.5,-47 497.5,-41 497.5,-41 497.5,-12 497.5,-12 497.5,-6 503.5,0 509.5,0 509.5,0 592.5,0 592.5,0 598.5,0 604.5,-6 604.5,-12 604.5,-12 604.5,-41 604.5,-41 604.5,-47 598.5,-53 592.5,-53\"/>\n<text text-anchor=\"middle\" x=\"551\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.059</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 33</text>\n<text text-anchor=\"middle\" x=\"551\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [32, 1]</text>\n</g>\n<!-- 5&#45;&gt;10 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M490.1409,-88.9777C499.1498,-79.7292 508.9048,-69.7147 517.9109,-60.4691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"520.4739,-62.8539 524.9445,-53.2485 515.4596,-57.9696 520.4739,-62.8539\"/>\n</g>\n</g>\n</svg>\n"},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"3uB28SYZi0jF","colab_type":"text"},"source":["How does the number of decision rules affect the accuracy of the model? We'll retrain the model 29 times to see how the accuracy changes as we increase the number of decision rules from 2 to 30."]},{"cell_type":"code","metadata":{"id":"VbZM0Vj4eCkV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1595338677059,"user_tz":240,"elapsed":84406,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"15019537-55c9-4bc2-85ae-8eb00b55990a"},"source":["for leaves in range(2, 31):\n","  clf = tree.DecisionTreeClassifier(max_leaf_nodes = leaves)\t\n","  clf = clf.fit(traindat, trainlabs)\t\n","  yhat = clf.predict(testdat)\n","  acc = sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)\n","  print(leaves,acc)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["2 0.888\n","3 0.913\n","4 0.931\n","5 0.937\n","6 0.9415\n","7 0.942\n","8 0.9385\n","9 0.9425\n","10 0.945\n","11 0.9475\n","12 0.9505\n","13 0.952\n","14 0.9525\n","15 0.9535\n","16 0.9535\n","17 0.9535\n","18 0.959\n","19 0.959\n","20 0.9585\n","21 0.96\n","22 0.957\n","23 0.9575\n","24 0.958\n","25 0.9585\n","26 0.9585\n","27 0.9585\n","28 0.958\n","29 0.9585\n","30 0.9585\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fzPXwVdEjM2b","colab_type":"text"},"source":["Let's now fit a naive Bayes model and print the accuracy of the model\n"]},{"cell_type":"code","metadata":{"id":"YKyZtRHgkWJT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595338679921,"user_tz":240,"elapsed":84981,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"b62bee12-11cd-4e1f-eb64-ead04fa38b81"},"source":["clf = MultinomialNB().fit(traindat, trainlabs)\n","clf = clf.fit(traindat, trainlabs)\t\n","yhat = clf.predict(testdat)\n","acc = sum([yhat[i] == testlabs[i] for i in range(len(testdat))])/len(testdat)\n","acc"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.985"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"8tuVd6zVpdvJ","colab_type":"text"},"source":["We can also calculate the confusion matrix of the model, a table of the following counts:\n","\n","True Negatives False Positives\n","\n","False Negatives True Positives"]},{"cell_type":"code","metadata":{"id":"usa3eGx6eK4w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595310916501,"user_tz":240,"elapsed":537,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"1a43be9a-ee98-4500-8e13-fc82ffedc04d"},"source":["print(confusion_matrix(testlabs, yhat))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[1724    5]\n"," [  25  246]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v91_evRmkMvx","colab_type":"text"},"source":["Let's visualize how Naive Bayes combines information from words in a sentence to make a judgement."]},{"cell_type":"code","metadata":{"id":"WpNi9hRalhK6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595339297816,"user_tz":240,"elapsed":836,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["import numpy as np\n","\n","def plotsentence(sentence, clf):\n","  acc = 1.0\n","  labs = []\n","  facs = []\n","  factor = np.exp(clf.class_log_prior_[0]- clf.class_log_prior_[1])\n","  labs += [\"PRIOR\"]\n","  facs += [factor]\n","  acc *= factor\n","  for w in sentence:\n","    i = word_dict[w]\n","    factor = np.exp(clf.feature_log_prob_[0][i]- clf.feature_log_prob_[1][i])\n","    labs += [w]\n","    facs += [factor]\n","    acc *= factor\n","  labs += [\"POST\"]\n","  facs += [acc]\n","  return((labs,facs))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"NA6qDQQ8qque","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1595342696614,"user_tz":240,"elapsed":749,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"f942581d-c1e6-45ee-a90a-ec262c10b4cb"},"source":["(labs,facs) = plotsentence(['yo', 'come', 'over', 'carlos', 'will', 'be', 'here', 'soon'], clf)\n","facs = [ fac if fac >= 1.0 else -1/fac for fac in facs ]\n","[(l,round(f,1)) for (l,f) in zip(labs,facs)]"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('PRIOR', 6.5),\n"," ('yo', 8.0),\n"," ('come', 15.5),\n"," ('over', 1.4),\n"," ('carlos', 4.9),\n"," ('will', 1.9),\n"," ('be', 1.4),\n"," ('here', 6.7),\n"," ('soon', 3.4),\n"," ('POST', 347592.0)]"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"YmveTDZ4y_jo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595342731119,"user_tz":240,"elapsed":578,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"786cc3f9-46c9-4584-e7b2-b6002372a63f"},"source":["(labs,facs) = plotsentence(['congratulations', 'thanks', 'to', 'a', 'good', 'friend', 'u', 'have', 'won'], clf)\n","facs = [ fac if fac >= 1.0 else -1/fac for fac in facs ]\n","[(l,round(f,1)) for (l,f) in zip(labs,facs)]"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('PRIOR', 6.5),\n"," ('congratulations', -11.4),\n"," ('thanks', -1.1),\n"," ('to', -1.4),\n"," ('a', -1.2),\n"," ('good', 4.7),\n"," ('friend', -1.3),\n"," ('u', 2.0),\n"," ('have', -1.1),\n"," ('won', -12.6),\n"," ('POST', -6.0)]"]},"metadata":{"tags":[]},"execution_count":68}]}]}
