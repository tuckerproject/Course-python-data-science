{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L19aux.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xI6VvT855Sdr","colab_type":"text"},"source":["In this notebook we'll be working with generative adversarial models (GANs).  \n","\n","`make_pos` defines a starircase array of size `d`. To start, a bunch of 0-1 uniform random numbers are arranged as an `m`x`d` matrix. The code then does a running sum, also known as a cumulative sum or `cumsum`, across the rows of the matrix. `numpy` refers to moving across the rows as traversing axis 1 of the matrix, so that’s the parameter value we use in the call.\n","\n","So, now we no longer have a bunch of random numbers between 0 and 1. Instead, each row contains the running sum at each location. This procedure guarantees an increasing sequence, with a starting value that is somewhere between 0 and 1 and an ending value around 10.0. It’s not a staircase yet, since a staircase goes from 0 to 1. We can rescale these values so they are in the right range. First, we grab the minimums or mins of each row, in a vector `X` . Since the rows are increasing, the min must be on the far left. We subtract off these `mins`.\n","\n","We then grab the maximum, `maxs`, of each row. They are on the far right. We divide the vector `X` by the max values so everything is in the 0-1 range as desired.\n"]},{"cell_type":"code","metadata":{"id":"BFVE6B_2aBeg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596682570334,"user_tz":240,"elapsed":879,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["import matplotlib.pyplot as plt\n","\n","# Create a dataset of vectors\n","import numpy as np\n","\n","# vector dimension\n","d = 20\n","# number of training examples\n","m = 10000\n","\n","def make_pos(m,d):\n","  X = np.cumsum(np.random.uniform(0,1, size=(m,d)),axis=1)\n","  mins = X[:,0]\n","  X = X - mins.reshape(m,1)\n","  maxs = X[:,(d-1)]\n","  X = X / maxs.reshape(m,1)\n","  return(X)\n","\n","Xpos = make_pos(m,d)\n","Xneg = make_pos(m,d)\n","Xneg = np.apply_along_axis(np.random.permutation, 1, Xneg)\n","X = np.concatenate((Xpos,Xneg))\n","#y = np.concatenate((np.repeat([0,1],m), np.repeat([1,0],m)))\n","y = np.concatenate((np.concatenate((np.repeat(1,m).reshape(m,1),np.repeat(0,m).reshape(m,1)),axis=1),\n","  np.concatenate((np.repeat(0,m).reshape(m,1),np.repeat(1,m).reshape(m,1)),axis=1)))\n","\n","# split into training and testing\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMnNkroXHPdD","colab_type":"text"},"source":["Then, we’ll get a `model` to learn to produce these artificially generated, one-dimensional grayscale staircases. Staircases are a nice stand-in for the more complex 2-dimensional color images that GANs typically produce.\n","\n","For our classifier, we’ll create a simple neural network using `Keras`. Our `model` has `d=20` input units to correspond to the 20 steps. There are 10 hidden units that the `model` can use to compute. And, there are 2 output units, corresponding to “staircase” or “not staircase”. \n","\n","The predictions in the output layer use a `softmax` activation. `softmax` accentuates the largest value in a vector, then normalizes the values to look like probabilities. That is, the values from `softmax` are between zero and 1 and sum up to 1.\n"]},{"cell_type":"code","metadata":{"id":"ScX_kjcPg0BW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1596682583675,"user_tz":240,"elapsed":10695,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"12f51071-0faf-4417-a894-39e895014e0e"},"source":["# set up a keras classifier\n","!pip install keras=='2.3.1'\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras import Model\n","\n","input = Input((d,))\n","x = Dense(10, activation='relu')(input)\n","out = Dense(2, activation='softmax',name='predict')(x)\n","\n","model = Model(input, out)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting keras==2.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n","\r\u001b[K     |▉                               | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n","Installing collected packages: keras-applications, keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.3.1 keras-applications-1.0.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kj_Zpk8pJQpH","colab_type":"text"},"source":["Below we compile the model.  We'll use a `mean_squared_error` `loss`, use `adam` as our `optimizer`, and record `accuracy` when printing our metrics."]},{"cell_type":"code","metadata":{"id":"l3E2f7mQkmkw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596682583676,"user_tz":240,"elapsed":5055,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# compile the keras model\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdXkIw-IJSmr","colab_type":"text"},"source":["We train the model, looping through all the training  data `epochs = 15` times."]},{"cell_type":"code","metadata":{"id":"yc8I_JJjpGqH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1596684387297,"user_tz":240,"elapsed":23349,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"0bf9b6a7-2ed4-4fbe-88e7-dadb48545d5d"},"source":["# train\n","\n","model.fit(X_train, y_train, epochs=15, batch_size=10)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 2.1474e-05 - accuracy: 1.0000\n","Epoch 2/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 1.7496e-05 - accuracy: 1.0000\n","Epoch 3/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 1.1766e-05 - accuracy: 1.0000\n","Epoch 4/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 9.7397e-06 - accuracy: 1.0000\n","Epoch 5/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 4.1343e-05 - accuracy: 1.0000\n","Epoch 6/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 5.7074e-06 - accuracy: 1.0000\n","Epoch 7/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 4.0196e-06 - accuracy: 1.0000\n","Epoch 8/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 8.8127e-06 - accuracy: 1.0000\n","Epoch 9/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 7.6079e-06 - accuracy: 1.0000\n","Epoch 10/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 3.2580e-06 - accuracy: 1.0000\n","Epoch 11/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 3.2699e-06 - accuracy: 1.0000\n","Epoch 12/15\n","1000/1000 [==============================] - 1s 1ms/step - loss: 2.6242e-06 - accuracy: 1.0000\n","Epoch 13/15\n","1000/1000 [==============================] - 1s 1ms/step - loss: 1.4247e-05 - accuracy: 1.0000\n","Epoch 14/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 1.6765e-06 - accuracy: 1.0000\n","Epoch 15/15\n","1000/1000 [==============================] - 2s 2ms/step - loss: 1.2015e-06 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f21faf07be0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"QEd5AkZjLM2x","colab_type":"text"},"source":["Below we import another `keras` module we'll be using to build our models."]},{"cell_type":"code","metadata":{"id":"vQ4P3TxPxXKW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596684015323,"user_tz":240,"elapsed":346,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["from tensorflow.keras import backend as K"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3uPp_1wrLZGi","colab_type":"text"},"source":["Our `misordered` function counts the number of time an example in our data set is out of order realtive to its neighbors."]},{"cell_type":"code","metadata":{"id":"elqjdV6R3cpB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596684018868,"user_tz":240,"elapsed":321,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["def misordered(l):\n","  bad = 0\n","  for i in range(len(l)-1):\n","    for j in range(i+1, len(l)):\n","      if l[i] > l[j]: bad += 1\n","  return(bad)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSuj2xBBL4jI","colab_type":"text"},"source":["Below are some example images from our training set with their labels."]},{"cell_type":"code","metadata":{"id":"x29bs2ivMLNq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1596684021641,"user_tz":240,"elapsed":344,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"816ba657-be0a-40e5-a41c-4d59dbf1e809"},"source":["# show some examples\n","from keras.preprocessing import image\n","\n","def make_image(v):\n","  v = v.reshape(1,d,1)\n","  v = np.concatenate((v,v,v,v,v))\n","  img = image.array_to_img(v)\n","  return(img)\n","\n","for i in range(10):\n","  display(make_image(X_train[i]))\n","  print(y_train[i])"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAJElEQVR4nGOUPsJZHv5aXNni+9+fR68n271MOKTLxIAFUCgIANZcCn9HO8PzAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC080>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAJElEQVR4nGNI0GNoW3nB/MEbBY5D/4uD3jAsn+LExIAFUCgIAI6OCbAan5yeAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC0F0>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAI0lEQVR4nGNkYBbl4+Xi42ASYpSS5eAWFWLnFWJiwAIoFAQAX3sBCaWtDl8AAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC080>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAI0lEQVR4nGNk4OGVlBZjEmdiZxHnFWBnE+TkEmRiwAIoFAQAYNoBCX60u6sAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC3C8>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAJElEQVR4nGNgeNIS8/+ZzkynfJZeO+bvYsfXFt9jYsACKBQEAJo7Ccx2o9rJAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC0F0>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAI0lEQVR4nGNkEBLhZhdhF+Fi5GIXExcTZmQX5mZiwAIoFAQAYEEBCVD81wcAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC080>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAI0lEQVR4nGNkYBESFRDkFuUUYuER4Rdl4+Tk5WZiwAIoFAQAYJABCV0glD0AAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC3C8>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAI0lEQVR4nGNkEBCXZGOVFREW4xZlZWdmYuDmFmZiwAIoFAQAYZ4BCX7NuG4AAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC0F0>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAJElEQVR4nGN4z2Czi2NByv8VTh/KlK/EPK6y62BgYsACKBQEAJrkCb+/t2G6AAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC3C8>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAAAAABgaJPvAAAAJElEQVR4nGN4lyj9rrvhf/qmzSs9/F4anVRSYKhkYsACKBQEAMV6ChW6WkczAAAAAElFTkSuQmCC\n","text/plain":["<PIL.Image.Image image mode=L size=20x5 at 0x7F21FB7DC080>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eWCzgl3LgaJe","colab_type":"text"},"source":["Now that we can accurately discriminate between staircase images and scrambled staircase images, let’s use the gradient approach to turn a non-staircase into a staircase.\n","\n","We’ll take steps in the direction of the computed gradient until the image is recognized with over 95 percent confidence as a staircase.\n","\n","We want the staircase, which is represented by the vector `input_data`, to remain a valid image. To keep the values of the vector in the right range, we reset back to zero any values in `input_data` that have gone negative.\n"]},{"cell_type":"code","metadata":{"id":"IimkRSkewxr5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"error","timestamp":1596684025296,"user_tz":240,"elapsed":456,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"62cc5a65-94c8-40ca-cffb-06d2ac95c647"},"source":["import random\n","\n","# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n","before = 0\n","after = 0\n","for i in range(10):\n","  layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n","\n","  target_class = 0\n","\n","  learning_rate = 0.0001\n","\n","  input_tensor = model.input\n","\n","  x = layer_dict['predict'].output[:, target_class]\n","  objective = K.sum(x)\n","  grads = K.gradients(objective, input_tensor)[0]\n","  grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-12)\n","  iterate = K.function([input_tensor], [objective, grads])\n","\n","  input_data = Xneg[i]\n","\n","  print(input_data)\n","\n","  print(misordered(input_data))\n","\n","  before += misordered(input_data)\n","  print(input_data)\n","  print(model.predict(input_data.reshape(1,-1)))\n","  make_image(input_data)\n","\n","  loss_value = 0.0\n","  while loss_value < 0.95: \n","    loss_value, grads_value = iterate(input_data.reshape(1,-1))\n","\n","    input_data += learning_rate * grads_value[0]\n","    input_data[input_data <0 ] = 0.0\n","    if random.random() < 0.01: print(\"**\",loss_value, input_data)\n","\n","  print(misordered(input_data))\n","  after += misordered(input_data)\n","  print(input_data)\n","  print(model.predict(input_data.reshape(1,-1)))\n","  make_image(input_data)"],"execution_count":23,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-80355f1e4e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mgrads\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0miterate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3967\u001b[0m   \"\"\"\n\u001b[1;32m   3968\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 3969\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   3970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."]}]},{"cell_type":"markdown","metadata":{"id":"eJtaAk9qgo8A","colab_type":"text"},"source":["Here's the constructed sequence that the discriminator thinks is a staircase."]},{"cell_type":"code","metadata":{"id":"jo-EJ5rpxg_0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596683973491,"user_tz":240,"elapsed":325,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"e9aab4ad-f8a2-44f2-bce2-fe38886b9ada"},"source":["input_data"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.9436739 , 0.92796105, 0.16642212, 0.61752079, 0.98875052,\n","       0.56660347, 0.64605225, 0.82673424, 0.62387285, 0.35658359,\n","       0.4564223 , 0.82857836, 0.07512545, 0.07262095, 0.09894495,\n","       0.21133531, 0.00147751, 0.23410808, 0.60519986, 0.72359434])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"O72ad4SgMSbS","colab_type":"text"},"source":["Below we'll learn to generate staircase images using a GAN\n","\n","\n","So, let’s try the GAN idea. It’s adversarial, so we need to construct two networks.\n","\n","We define our discriminator using `build_discriminator`. The discriminator network takes as input a vector of size `d=20` representing the purported staircase. It has two fully connected or dense sets of weights leading to hidden layers, each of size `d/2` = 10. Finally, the output layer is a single unit that should output 1 for a real staircase and 0 for a fake one.\n","\n","Since we know this output value is between zero and one, we can use a `sigmoid` activation function. `sigmoid` smoothly transitions from near-zero values for negative inputs to near-one values for positive inputs, which guarantees the outputs stay in a zero-to-one range.\n","\n","We build the generator using `build_generator`. The generator has a similar structure to the discriminator. This network-structured generator maps a vector of `noise` into a staircase vector. The number of components of the noise vector can be thought of as a latent dimensionality of the image space --- the more noise components, the higher the latent dimensionality. We’ll use `latent_dim = 50` to be a variable that specifies the number of random values we’ll use as our input so the network would have a large pool of random values to choose from.\n","\n","The generator uses a dense layer of weights to map the chosen 18 random values to a hidden layer, where the number of hidden units is 2*d = 40. The generator then has another Dense layer of size d=20, then an output layer of size `d=20`. Since all of the outputs should be between zero and one, I set the activation function for the output layer to be a sigmoid for each of these units.\n"]},{"cell_type":"code","metadata":{"id":"_BDVfQbWtksB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596683980488,"user_tz":240,"elapsed":315,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# Let's try a GAN on it.\n","# from https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py\n","\n","from keras.optimizers import Adam\n","\n","import matplotlib.pyplot as plt\n","\n","def build_generator():\n","  noise = Input(shape=(latent_dim,))\n","  x = Dense(2*d, activation='relu')(noise)\n","  x = Dense(d, activation='relu')(x)\n","  out = Dense(d, activation='sigmoid')(x)\n","  model = Model(noise, out)\n","  return(model)\n","\n","def build_discriminator():\n","  input = Input((d,))\n","  x = Dense(d//2, activation='relu')(input)\n","  x = Dense(d//2, activation='relu')(x)\n","  out = Dense(1, activation='sigmoid',name='predict')(x)\n","  model = Model(input, out)\n","  return(model)\n","\n","def save_imgs(epoch):\n","  swaps = 0\n","  # fake\n","  for i in range(10):\n","    noise = np.random.normal(0, 1, (1, latent_dim))\n","    gen_img = generator.predict(noise)\n","    display(make_image(gen_img))\n","    label = discriminator.predict(gen_img)\n","    print(label)\n","    swaps += misordered(gen_img[0])\n","  print(swaps/10)\n","  # real\n","  for i in range(10):\n","    gen_img = X[i].reshape(1,d)\n","    display(make_image(gen_img))\n","    label = discriminator.predict(gen_img)\n","    print(label)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWJvXbQaNceC","colab_type":"text"},"source":["We’ll use the `Adam` optimizer for training, and we’ll train for `epochs=300`. The `Adam` optimizer is an adaptive algorithm introduced in 2015 that controls the process of gradient descent by optimizing the rate of learning at each step of the optimization process. Adam generally does a good job, and it quickly became a default choice for training networks.\n","\n","We’ll give the networks a `batch_size` of 128 examples in each epoch.\n","We’ll set up our training set `X` using only positive examples of staircases. We force `X` to be the right shape for the network by calling `expand_dims` to add another dimension.\n","\n","We also create targets for learning --- we use ones for valid examples of staircases from the training set `X` and zeros for fake examples that come out of the generator.\n","Next, we construct the combined network. We build the discriminator and set it up to be trained.\n","\n","We can then instantiate a generator, `z`, which will take noise inputs and produce images, `img`.\n","\n","We want to train the generator to make staircases that the discriminator cannot reliably distinguish from the real staircase images. \n","\n"," The weights of the discriminator need to remain constant while we update the generator. If we did not hold the discriminator’s weights fixed, gradient descent would \"solve\" the problem of fooling the discriminator merely by making the DISCRIMINATOR less accurate. So, we set `discriminator.trainable` for the combined network to `False`.\n","\n","The discriminator assesses the generator's image output img and produces a judgment as to whether the image is `valid`. The combined network, end to end, connects the input` z` to the output called “valid”."]},{"cell_type":"code","metadata":{"id":"SvkcOlDd2D6A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"error","timestamp":1596683985414,"user_tz":240,"elapsed":473,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"78dd09f7-9896-4297-c8fe-d9871b4eea97"},"source":["# Run the GAN\n","latent_dim = 50\n","optimizer = Adam(0.0002, 0.5)\n","epochs = 30000\n","\n","# Build and compile the discriminator\n","discriminator = build_discriminator()\n","\n","# Build the generator\n","generator = build_generator()\n","\n","# The generator takes noise as input and generates an image\n","z = Input(shape=(latent_dim,))\n","img = generator(z)\n","\n","# The discriminator takes generated images as input and determines validity\n","valid = discriminator(img)\n","\n","# The combined model (stacked generator and discriminator)\n","combined = Model(z, valid)\n","\n","X = Xpos\n","batch_size = 128\n","save_interval = 10\n","\n","# Adversarial ground truths\n","valid = np.ones((batch_size, 1))\n","fake = np.zeros((batch_size, 1))\n","\n","for epoch in range(epochs):\n","  # Select a random half of images\n","  idx = np.random.randint(0, X.shape[0], batch_size)\n","  imgs = X[idx]\n","\n","  # Sample noise and generate a batch of new images\n","  noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","  gen_imgs = generator.predict(noise)\n","\n","  # Train the discriminator (real classified as valid/ones and generated as fake/zeros)\n","  discriminator.trainable = True\n","  discriminator.compile(loss='mean_squared_error',\n","                optimizer=optimizer,\n","                metrics=['accuracy'])\n","  for i in range(100):\n","    d_loss_real = discriminator.train_on_batch(imgs, valid)\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","  # Train the generator (wants discriminator to mistake images as real)\n","  discriminator.trainable = False\n","  combined.compile(loss='mean_squared_error', optimizer=optimizer)\n","\n","  g_loss = combined.train_on_batch(noise, valid)\n","\n","  # If at save interval => save generated image samples\n","  if epoch % save_interval == 0 or epoch == epochs - 1:\n","                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","                save_imgs(epoch)"],"execution_count":19,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-dcccd7bd4742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   discriminator.compile(loss='mean_squared_error',\n\u001b[1;32m     42\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 metrics=['accuracy'])\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[1;32m    543\u001b[0m           loss, loss_weights, output_names=self.output_names)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    565\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m       \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m       if (self._dtype_policy.loss_scale is not None and\n\u001b[1;32m    563\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    901\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     raise ValueError(\n\u001b[0;32m--> 903\u001b[0;31m         'Could not interpret optimizer identifier: {}'.format(identifier))\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.optimizers.Adam object at 0x7f21fb95bda0>"]}]}]}
