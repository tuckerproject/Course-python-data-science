{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L16.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OydShklHHtdh","colab_type":"text"},"source":["In this notebook, we'll build a model to classify online posts about baseball and hockey.\n","\n","Below we download the online posts data."]},{"cell_type":"code","metadata":{"id":"ofSSY-oGw8rw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595012752160,"user_tz":240,"elapsed":10164,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"00e815e1-8647-40b3-8319-96dad89cd226"},"source":["from sklearn.datasets import fetch_20newsgroups\n","# from sklearn.feature_extraction.text import TfidfVectorizer\n","groups = ['rec.sport.baseball', 'rec.sport.hockey']\n","newsgroups = fetch_20newsgroups(subset='all', remove = ['headers', 'footers', 'quotes'], categories = groups)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tbhmnw-Ewyk7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595012755705,"user_tz":240,"elapsed":954,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["# from sklearn.naive_bayes import MultinomialNB\n","# from sklearn import metrics\n","# newsgroups_test = fetch_20newsgroups(subset='test', remove = ['headers', 'footers', 'quotes'], categories = groups)\n","# vectors_test = vectorizer.transform(newsgroups_test.data)\n","# clf = MultinomialNB(alpha=.01)\n","# clf.fit(vectors, newsgroups_train.target)\n","# pred = clf.predict(vectors_test)\n","# metrics.f1_score(newsgroups_test.target, pred, average='macro')\n","# 0.88213592402729568 (full set)\n","# 0.9320767597087378"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t4GDNzTYIqso","colab_type":"text"},"source":["Next, we download GloVe vectors we will be using to represent our post data."]},{"cell_type":"code","metadata":{"id":"sCjJULtUqjAe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1595013150875,"user_tz":240,"elapsed":392411,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"4128c948-da89-4089-e231-26dc441fb41e"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2020-07-17 19:05:59--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2020-07-17 19:05:59--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2020-07-17 19:06:00--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  2.13MB/s    in 6m 29s  \n","\n","2020-07-17 19:12:29 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GZsutIRzJCzg","colab_type":"text"},"source":["Below we unzip the GloVe file we downloaded."]},{"cell_type":"code","metadata":{"id":"5j_YyS37qv7m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1595013178290,"user_tz":240,"elapsed":416949,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"aba3e613-1497-4e2b-eb49-9786c9ae3756"},"source":["!unzip glove.6B.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lmi-6INoJHbv","colab_type":"text"},"source":["Next, we load the GloVe vectors."]},{"cell_type":"code","metadata":{"id":"siJVA4bpyPY8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595013188105,"user_tz":240,"elapsed":423765,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"ba3ff00e-d4b8-4b65-8051-0bd048a83712"},"source":["import numpy as np\n","\n","embeddings_index = {}\n","f = open('glove.6B.100d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zzij4IlhJMsE","colab_type":"text"},"source":["Next, we convert the data to a collection of word GloVe word vectors for each of the words in our dataset."]},{"cell_type":"code","metadata":{"id":"CB7FMHUsI4WD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1595013195861,"user_tz":240,"elapsed":7735,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"f4ebc1c9-f87f-47c2-a966-a60cbf46170e"},"source":["!pip install keras=='2.3.1'\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","print('Preparing embedding matrix.')\n","MAX_NUM_WORDS = 20000\n","MAX_SEQUENCE_LENGTH = 1000\n","EMBEDDING_DIM = 100\n","\n","tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(newsgroups.data)\n","sequences = tokenizer.texts_to_sequences(newsgroups.data)\n","\n","word_index = tokenizer.word_index\n","\n","# prepare embedding matrix\n","num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i >= MAX_NUM_WORDS:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Preparing embedding matrix.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BuuAUWLxJqe-","colab_type":"text"},"source":["Next, we'll build our dataset for training, `data` and `labels`, as well as our test set, `data_test` and `labels_test`.  We will limit our training set to 200 examples."]},{"cell_type":"code","metadata":{"id":"71Npelu5XOXI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1595013196282,"user_tz":240,"elapsed":8145,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"aeaad698-c2f1-4bd4-efc9-422298ffeb70"},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","# finally, vectorize the text samples into a 2D integer tensor\n","MAX_NUM_WORDS = 20000\n","MAX_SEQUENCE_LENGTH = 1000\n","\n","tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(newsgroups.data)\n","sequences = tokenizer.texts_to_sequences(newsgroups.data)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = to_categorical(np.asarray(newsgroups.target))\n","\n","# print(data.shape)\n","\n","data, data_test, labels, labels_test = train_test_split(data,labels,train_size=200)\n","\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","print('Shape of data_test tensor:', data_test.shape)\n","print('Shape of label_test tensor:', labels_test.shape)\n","\n","# split the data into a training set and a validation set\n","# indices = np.arange(data.shape[0])\n","# np.random.shuffle(indices)\n","# data = data[indices]\n","# labels = labels[indices]\n","# num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n","\n","# x_train = data[:-num_validation_samples]\n","# y_train = labels[:-num_validation_samples]\n","# x_val = data[-num_validation_samples:]\n","# y_val = labels[-num_validation_samples:]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 18135 unique tokens.\n","Shape of data tensor: (200, 1000)\n","Shape of label tensor: (200, 2)\n","Shape of data_test tensor: (1793, 1000)\n","Shape of label_test tensor: (1793, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Q80Hv4ZMM14","colab_type":"text"},"source":["Next, we'll declare a `train` function that declares and trains the model with `pretrain` weights.  "]},{"cell_type":"code","metadata":{"id":"MG5dKkuxW95S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595013196283,"user_tz":240,"elapsed":8142,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}}},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding\n","from keras.models import Model\n","from keras.initializers import Constant\n","# from keras.optimizers import RMSprop\n","# from keras.optimizers import Adam\n","from keras import optimizers\n","\n","EMBEDDING_DIM = 100\n","\n","# load pre-trained word embeddings into an Embedding layer\n","# note that we set trainable = False so as to keep the embeddings fixed\n","# num_words = len(vectorizer.vocabulary_)\n","# num_words = len(word_index)+1\n","\n","def train(pretrain):\n","  if not pretrain:  # train your own embedding\n","    embedding_layer = Embedding(num_words,\n","                              EMBEDDING_DIM,\n","                              input_length=MAX_SEQUENCE_LENGTH,\n","                              trainable=True\n","                             )\n","  else:\n","      embedding_layer = Embedding(num_words,\n","                              EMBEDDING_DIM,\n","                              embeddings_initializer=Constant(embedding_matrix),\n","                              input_length=MAX_SEQUENCE_LENGTH,\n","                              trainable=False\n","                           )\n","  print('Training model.')\n","\n","  # train a 1D convnet with global maxpooling\n","  sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","\n","  embedded_sequences = embedding_layer(sequence_input)\n","  x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n","  x = MaxPooling1D(5)(x)\n","  x = Conv1D(128, 5, activation='relu')(x)\n","  x = MaxPooling1D(5)(x)\n","  x = Conv1D(128, 5, activation='relu')(x)\n","  x = GlobalMaxPooling1D()(x)\n","  x = Dense(128, activation='relu')(x)\n","  preds = Dense(len(groups), activation='softmax')(x)\n","\n","  solver = optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","\n","  model = Model(sequence_input, preds)\n","  model.compile(loss='categorical_crossentropy',\n","                optimizer=solver,\n","                metrics=['acc'])\n","\n","  model.fit(data, labels,\n","            epochs=100,\n","            validation_data=(data_test, labels_test))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Ufl-EMEMn7L","colab_type":"text"},"source":["Below we train the model without pretrained weights."]},{"cell_type":"code","metadata":{"id":"cBFzGzyqXKGk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595013240490,"user_tz":240,"elapsed":52342,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"db9c8a0a-f1c3-4adb-a2bb-fd6350e10127"},"source":["train(False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Training model.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 200 samples, validate on 1793 samples\n","Epoch 1/100\n","200/200 [==============================] - 8s 38ms/step - loss: 0.6949 - acc: 0.5150 - val_loss: 0.6943 - val_acc: 0.4964\n","Epoch 2/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.6807 - acc: 0.5450 - val_loss: 0.6951 - val_acc: 0.4964\n","Epoch 3/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.6680 - acc: 0.5450 - val_loss: 0.6963 - val_acc: 0.4964\n","Epoch 4/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.6534 - acc: 0.5450 - val_loss: 0.6987 - val_acc: 0.4964\n","Epoch 5/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.6319 - acc: 0.5800 - val_loss: 0.6940 - val_acc: 0.5148\n","Epoch 6/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.5998 - acc: 0.7550 - val_loss: 0.7023 - val_acc: 0.5125\n","Epoch 7/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.5474 - acc: 0.7500 - val_loss: 0.6755 - val_acc: 0.5700\n","Epoch 8/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.4729 - acc: 0.8800 - val_loss: 0.6519 - val_acc: 0.6213\n","Epoch 9/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.3641 - acc: 0.9650 - val_loss: 0.6047 - val_acc: 0.7384\n","Epoch 10/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.2335 - acc: 0.9750 - val_loss: 0.6033 - val_acc: 0.6364\n","Epoch 11/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9750 - val_loss: 0.4729 - val_acc: 0.7914\n","Epoch 12/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0656 - acc: 0.9800 - val_loss: 0.4389 - val_acc: 0.7897\n","Epoch 13/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0449 - acc: 0.9950 - val_loss: 0.4393 - val_acc: 0.7842\n","Epoch 14/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0266 - acc: 0.9950 - val_loss: 0.4179 - val_acc: 0.8098\n","Epoch 15/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0188 - acc: 0.9900 - val_loss: 0.4076 - val_acc: 0.8031\n","Epoch 16/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4020 - val_acc: 0.8081\n","Epoch 17/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4147 - val_acc: 0.8137\n","Epoch 18/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4054 - val_acc: 0.8098\n","Epoch 19/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.8171\n","Epoch 20/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4280 - val_acc: 0.8126\n","Epoch 21/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4176 - val_acc: 0.8098\n","Epoch 22/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.8093\n","Epoch 23/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4618 - val_acc: 0.7925\n","Epoch 24/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.8037\n","Epoch 25/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.8104\n","Epoch 26/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.0018e-04 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.8104\n","Epoch 27/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.6277e-04 - acc: 1.0000 - val_loss: 0.4704 - val_acc: 0.8104\n","Epoch 28/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.2134e-04 - acc: 1.0000 - val_loss: 0.4572 - val_acc: 0.8115\n","Epoch 29/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.1969e-04 - acc: 1.0000 - val_loss: 0.4571 - val_acc: 0.8109\n","Epoch 30/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.6769e-04 - acc: 1.0000 - val_loss: 0.4610 - val_acc: 0.8104\n","Epoch 31/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.2089e-04 - acc: 1.0000 - val_loss: 0.4646 - val_acc: 0.8065\n","Epoch 32/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.7743e-04 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.8070\n","Epoch 33/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.4231e-04 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.8098\n","Epoch 34/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.1337e-04 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.8104\n","Epoch 35/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.8918e-04 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8126\n","Epoch 36/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.7412e-04 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8076\n","Epoch 37/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.4791e-04 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8093\n","Epoch 38/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.2806e-04 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8070\n","Epoch 39/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.1438e-04 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8076\n","Epoch 40/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.9876e-04 - acc: 1.0000 - val_loss: 0.4929 - val_acc: 0.8070\n","Epoch 41/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.8708e-04 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.8037\n","Epoch 42/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.7700e-04 - acc: 1.0000 - val_loss: 0.4972 - val_acc: 0.8031\n","Epoch 43/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.5817e-04 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.8065\n","Epoch 44/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.5547e-04 - acc: 1.0000 - val_loss: 0.5086 - val_acc: 0.8076\n","Epoch 45/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.4560e-04 - acc: 1.0000 - val_loss: 0.5099 - val_acc: 0.8054\n","Epoch 46/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.3039e-04 - acc: 1.0000 - val_loss: 0.5089 - val_acc: 0.8048\n","Epoch 47/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.2443e-04 - acc: 1.0000 - val_loss: 0.5127 - val_acc: 0.7992\n","Epoch 48/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.2239e-04 - acc: 1.0000 - val_loss: 0.5137 - val_acc: 0.8009\n","Epoch 49/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.1421e-04 - acc: 1.0000 - val_loss: 0.5151 - val_acc: 0.8048\n","Epoch 50/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.0304e-04 - acc: 1.0000 - val_loss: 0.5170 - val_acc: 0.8037\n","Epoch 51/100\n","200/200 [==============================] - 0s 1ms/step - loss: 9.8136e-05 - acc: 1.0000 - val_loss: 0.5194 - val_acc: 0.8042\n","Epoch 52/100\n","200/200 [==============================] - 0s 1ms/step - loss: 9.3563e-05 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.8054\n","Epoch 53/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.9626e-05 - acc: 1.0000 - val_loss: 0.5214 - val_acc: 0.8048\n","Epoch 54/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.5473e-05 - acc: 1.0000 - val_loss: 0.5277 - val_acc: 0.8042\n","Epoch 55/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.1569e-05 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.8042\n","Epoch 56/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.6298e-05 - acc: 1.0000 - val_loss: 0.5309 - val_acc: 0.8042\n","Epoch 57/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.2552e-05 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.8031\n","Epoch 58/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.9888e-05 - acc: 1.0000 - val_loss: 0.5334 - val_acc: 0.8020\n","Epoch 59/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.7105e-05 - acc: 1.0000 - val_loss: 0.5347 - val_acc: 0.8026\n","Epoch 60/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.4254e-05 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.8048\n","Epoch 61/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.2159e-05 - acc: 1.0000 - val_loss: 0.5360 - val_acc: 0.8031\n","Epoch 62/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.1075e-05 - acc: 1.0000 - val_loss: 0.5369 - val_acc: 0.8031\n","Epoch 63/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.8661e-05 - acc: 1.0000 - val_loss: 0.5381 - val_acc: 0.8059\n","Epoch 64/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.6281e-05 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.8037\n","Epoch 65/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.3065e-05 - acc: 1.0000 - val_loss: 0.5417 - val_acc: 0.8042\n","Epoch 66/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.1717e-05 - acc: 1.0000 - val_loss: 0.5438 - val_acc: 0.8031\n","Epoch 67/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.0245e-05 - acc: 1.0000 - val_loss: 0.5457 - val_acc: 0.8031\n","Epoch 68/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.8377e-05 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.8031\n","Epoch 69/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.6910e-05 - acc: 1.0000 - val_loss: 0.5466 - val_acc: 0.8042\n","Epoch 70/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.4737e-05 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.8042\n","Epoch 71/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.3394e-05 - acc: 1.0000 - val_loss: 0.5525 - val_acc: 0.8037\n","Epoch 72/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.1979e-05 - acc: 1.0000 - val_loss: 0.5539 - val_acc: 0.8031\n","Epoch 73/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.0727e-05 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.8037\n","Epoch 74/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.9194e-05 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.8031\n","Epoch 75/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.8172e-05 - acc: 1.0000 - val_loss: 0.5554 - val_acc: 0.8037\n","Epoch 76/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.7182e-05 - acc: 1.0000 - val_loss: 0.5569 - val_acc: 0.8037\n","Epoch 77/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.6360e-05 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.8037\n","Epoch 78/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.5100e-05 - acc: 1.0000 - val_loss: 0.5585 - val_acc: 0.8031\n","Epoch 79/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.4326e-05 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.8026\n","Epoch 80/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.3377e-05 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.8037\n","Epoch 81/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.2501e-05 - acc: 1.0000 - val_loss: 0.5617 - val_acc: 0.8042\n","Epoch 82/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.1869e-05 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.8031\n","Epoch 83/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.1072e-05 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.8031\n","Epoch 84/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.0408e-05 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.8037\n","Epoch 85/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.9617e-05 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.8037\n","Epoch 86/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.9053e-05 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.8031\n","Epoch 87/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.8026e-05 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.8031\n","Epoch 88/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.7502e-05 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.8031\n","Epoch 89/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.6768e-05 - acc: 1.0000 - val_loss: 0.5689 - val_acc: 0.8037\n","Epoch 90/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.6234e-05 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.8037\n","Epoch 91/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.5485e-05 - acc: 1.0000 - val_loss: 0.5722 - val_acc: 0.8037\n","Epoch 92/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.4937e-05 - acc: 1.0000 - val_loss: 0.5744 - val_acc: 0.8026\n","Epoch 93/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.4136e-05 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.8026\n","Epoch 94/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.3646e-05 - acc: 1.0000 - val_loss: 0.5762 - val_acc: 0.8031\n","Epoch 95/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.2977e-05 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.8015\n","Epoch 96/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.2636e-05 - acc: 1.0000 - val_loss: 0.5815 - val_acc: 0.8015\n","Epoch 97/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.2039e-05 - acc: 1.0000 - val_loss: 0.5817 - val_acc: 0.8015\n","Epoch 98/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.1499e-05 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.8015\n","Epoch 99/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.0970e-05 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.8015\n","Epoch 100/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.0481e-05 - acc: 1.0000 - val_loss: 0.5824 - val_acc: 0.8026\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wFgJVqEjMsaR","colab_type":"text"},"source":["Next we train the model with pretrained weights."]},{"cell_type":"code","metadata":{"id":"Ni_xRrAmdN-X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595013281725,"user_tz":240,"elapsed":27071,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"c7386f72-8405-4216-fe47-60602cd1f7d2"},"source":["train(True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Training model.\n","Train on 200 samples, validate on 1793 samples\n","Epoch 1/100\n","200/200 [==============================] - 0s 2ms/step - loss: 0.7112 - acc: 0.5600 - val_loss: 0.6971 - val_acc: 0.5159\n","Epoch 2/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.6341 - acc: 0.6800 - val_loss: 0.6797 - val_acc: 0.5477\n","Epoch 3/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.5904 - acc: 0.7850 - val_loss: 0.6803 - val_acc: 0.5427\n","Epoch 4/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.5447 - acc: 0.8400 - val_loss: 0.7295 - val_acc: 0.4992\n","Epoch 5/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.4859 - acc: 0.8100 - val_loss: 0.6293 - val_acc: 0.6793\n","Epoch 6/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.4065 - acc: 0.9400 - val_loss: 0.6045 - val_acc: 0.6899\n","Epoch 7/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.3392 - acc: 0.9450 - val_loss: 0.5767 - val_acc: 0.7072\n","Epoch 8/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.2454 - acc: 0.9900 - val_loss: 0.5322 - val_acc: 0.7524\n","Epoch 9/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.1753 - acc: 0.9850 - val_loss: 0.5356 - val_acc: 0.6888\n","Epoch 10/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.1267 - acc: 0.9900 - val_loss: 0.4819 - val_acc: 0.7384\n","Epoch 11/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0891 - acc: 0.9900 - val_loss: 0.4361 - val_acc: 0.7719\n","Epoch 12/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0584 - acc: 0.9900 - val_loss: 0.4244 - val_acc: 0.7747\n","Epoch 13/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0416 - acc: 0.9950 - val_loss: 0.3873 - val_acc: 0.8020\n","Epoch 14/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.7312\n","Epoch 15/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.3588 - val_acc: 0.8305\n","Epoch 16/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.3501 - val_acc: 0.8360\n","Epoch 17/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.3498 - val_acc: 0.8338\n","Epoch 18/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3621 - val_acc: 0.8349\n","Epoch 19/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.3562 - val_acc: 0.8405\n","Epoch 20/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3648 - val_acc: 0.8344\n","Epoch 21/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.3625 - val_acc: 0.8405\n","Epoch 22/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.3615 - val_acc: 0.8394\n","Epoch 23/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.3705 - val_acc: 0.8377\n","Epoch 24/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.3632 - val_acc: 0.8461\n","Epoch 25/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3785 - val_acc: 0.8338\n","Epoch 26/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.3700 - val_acc: 0.8461\n","Epoch 27/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3729 - val_acc: 0.8450\n","Epoch 28/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3927 - val_acc: 0.8316\n","Epoch 29/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4040 - val_acc: 0.8327\n","Epoch 30/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3939 - val_acc: 0.8410\n","Epoch 31/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3975 - val_acc: 0.8388\n","Epoch 32/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4086 - val_acc: 0.8321\n","Epoch 33/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.3950 - val_acc: 0.8444\n","Epoch 34/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4078 - val_acc: 0.8366\n","Epoch 35/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4113 - val_acc: 0.8399\n","Epoch 36/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4096 - val_acc: 0.8427\n","Epoch 37/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4119 - val_acc: 0.8450\n","Epoch 38/100\n","200/200 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.8405\n","Epoch 39/100\n","200/200 [==============================] - 0s 1ms/step - loss: 9.7441e-04 - acc: 1.0000 - val_loss: 0.4334 - val_acc: 0.8366\n","Epoch 40/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.8877e-04 - acc: 1.0000 - val_loss: 0.4262 - val_acc: 0.8461\n","Epoch 41/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.2151e-04 - acc: 1.0000 - val_loss: 0.4316 - val_acc: 0.8472\n","Epoch 42/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.6256e-04 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.8444\n","Epoch 43/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.7207e-04 - acc: 1.0000 - val_loss: 0.4538 - val_acc: 0.8371\n","Epoch 44/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.2077e-04 - acc: 1.0000 - val_loss: 0.4540 - val_acc: 0.8383\n","Epoch 45/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.6664e-04 - acc: 1.0000 - val_loss: 0.4528 - val_acc: 0.8450\n","Epoch 46/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.0452e-04 - acc: 1.0000 - val_loss: 0.4559 - val_acc: 0.8450\n","Epoch 47/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.8973e-04 - acc: 1.0000 - val_loss: 0.4609 - val_acc: 0.8450\n","Epoch 48/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.3664e-04 - acc: 1.0000 - val_loss: 0.4683 - val_acc: 0.8422\n","Epoch 49/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.0988e-04 - acc: 1.0000 - val_loss: 0.4776 - val_acc: 0.8371\n","Epoch 50/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.7807e-04 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.8433\n","Epoch 51/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.4465e-04 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.8422\n","Epoch 52/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.2834e-04 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8427\n","Epoch 53/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.9863e-04 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.8410\n","Epoch 54/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.7713e-04 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8416\n","Epoch 55/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.6105e-04 - acc: 1.0000 - val_loss: 0.4967 - val_acc: 0.8383\n","Epoch 56/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.4213e-04 - acc: 1.0000 - val_loss: 0.5004 - val_acc: 0.8377\n","Epoch 57/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.2569e-04 - acc: 1.0000 - val_loss: 0.5029 - val_acc: 0.8399\n","Epoch 58/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.1654e-04 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.8332\n","Epoch 59/100\n","200/200 [==============================] - 0s 1ms/step - loss: 2.0023e-04 - acc: 1.0000 - val_loss: 0.5183 - val_acc: 0.8383\n","Epoch 60/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.8881e-04 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.8416\n","Epoch 61/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.7515e-04 - acc: 1.0000 - val_loss: 0.5239 - val_acc: 0.8349\n","Epoch 62/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.6264e-04 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8383\n","Epoch 63/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.5336e-04 - acc: 1.0000 - val_loss: 0.5143 - val_acc: 0.8455\n","Epoch 64/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.4939e-04 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.8461\n","Epoch 65/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.3767e-04 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.8427\n","Epoch 66/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.2943e-04 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.8450\n","Epoch 67/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.2739e-04 - acc: 1.0000 - val_loss: 0.5342 - val_acc: 0.8377\n","Epoch 68/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.1856e-04 - acc: 1.0000 - val_loss: 0.5360 - val_acc: 0.8388\n","Epoch 69/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.1355e-04 - acc: 1.0000 - val_loss: 0.5369 - val_acc: 0.8444\n","Epoch 70/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.0574e-04 - acc: 1.0000 - val_loss: 0.5375 - val_acc: 0.8433\n","Epoch 71/100\n","200/200 [==============================] - 0s 1ms/step - loss: 1.0098e-04 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.8399\n","Epoch 72/100\n","200/200 [==============================] - 0s 1ms/step - loss: 9.5185e-05 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.8388\n","Epoch 73/100\n","200/200 [==============================] - 0s 1ms/step - loss: 9.2349e-05 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.8410\n","Epoch 74/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.7450e-05 - acc: 1.0000 - val_loss: 0.5442 - val_acc: 0.8416\n","Epoch 75/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.4382e-05 - acc: 1.0000 - val_loss: 0.5463 - val_acc: 0.8433\n","Epoch 76/100\n","200/200 [==============================] - 0s 1ms/step - loss: 8.2720e-05 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.8450\n","Epoch 77/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.8640e-05 - acc: 1.0000 - val_loss: 0.5511 - val_acc: 0.8422\n","Epoch 78/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.4555e-05 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.8394\n","Epoch 79/100\n","200/200 [==============================] - 0s 1ms/step - loss: 7.2846e-05 - acc: 1.0000 - val_loss: 0.5566 - val_acc: 0.8388\n","Epoch 80/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.8948e-05 - acc: 1.0000 - val_loss: 0.5586 - val_acc: 0.8388\n","Epoch 81/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.7059e-05 - acc: 1.0000 - val_loss: 0.5610 - val_acc: 0.8388\n","Epoch 82/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.4614e-05 - acc: 1.0000 - val_loss: 0.5627 - val_acc: 0.8394\n","Epoch 83/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.2745e-05 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.8410\n","Epoch 84/100\n","200/200 [==============================] - 0s 1ms/step - loss: 6.0573e-05 - acc: 1.0000 - val_loss: 0.5664 - val_acc: 0.8394\n","Epoch 85/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.8252e-05 - acc: 1.0000 - val_loss: 0.5688 - val_acc: 0.8394\n","Epoch 86/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.6426e-05 - acc: 1.0000 - val_loss: 0.5695 - val_acc: 0.8394\n","Epoch 87/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.4268e-05 - acc: 1.0000 - val_loss: 0.5701 - val_acc: 0.8394\n","Epoch 88/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.3268e-05 - acc: 1.0000 - val_loss: 0.5720 - val_acc: 0.8394\n","Epoch 89/100\n","200/200 [==============================] - 0s 1ms/step - loss: 5.1286e-05 - acc: 1.0000 - val_loss: 0.5740 - val_acc: 0.8394\n","Epoch 90/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.9253e-05 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.8388\n","Epoch 91/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.8013e-05 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.8399\n","Epoch 92/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.7183e-05 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.8327\n","Epoch 93/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.5131e-05 - acc: 1.0000 - val_loss: 0.5878 - val_acc: 0.8360\n","Epoch 94/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.3323e-05 - acc: 1.0000 - val_loss: 0.5866 - val_acc: 0.8388\n","Epoch 95/100\n","200/200 [==============================] - 0s 1ms/step - loss: 4.2602e-05 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.8450\n","Epoch 96/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.9418e-05 - acc: 1.0000 - val_loss: 0.5859 - val_acc: 0.8438\n","Epoch 97/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.8351e-05 - acc: 1.0000 - val_loss: 0.5895 - val_acc: 0.8377\n","Epoch 98/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.6871e-05 - acc: 1.0000 - val_loss: 0.5918 - val_acc: 0.8366\n","Epoch 99/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.5689e-05 - acc: 1.0000 - val_loss: 0.5911 - val_acc: 0.8399\n","Epoch 100/100\n","200/200 [==============================] - 0s 1ms/step - loss: 3.4625e-05 - acc: 1.0000 - val_loss: 0.5925 - val_acc: 0.8410\n"],"name":"stdout"}]}]}
