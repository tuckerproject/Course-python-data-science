{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L24qs.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zYfDEH0WlLX5","colab_type":"text"},"source":["Privacy typically comes with a cost in terms of running time or accuracy. How significant is this cost? Train two naive Bayes classifiers on the spam detection dataset to get a sense of the differential cost of differential privacy. (In this case, there was no decrease in accuracy and no measurable increase in running time.)"]},{"cell_type":"markdown","metadata":{"id":"X5udgzCJk1Ay","colab_type":"text"},"source":["In this notebook, we will build a spam detector using two different naive Bayes model to get a sense of the difference in cost and accuracy for using a differentially private model.\n","\n","Import the libraries we'll be using."]},{"cell_type":"code","metadata":{"id":"LaH5v5MukzYG","colab_type":"code","colab":{}},"source":["from sklearn import tree\n","import graphviz \n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0jCtEvFclSNE","colab_type":"text"},"source":["Next we'll write a function to process the data into a dictionary of words and their number of occurances, `word_dict`, and a count of the number of words total, `lexiconsize`"]},{"cell_type":"code","metadata":{"id":"Qd_rFwbllOv8","colab_type":"code","colab":{}},"source":["# read in the vocabulary file \n","def readvocab(vocab_path=\"vocab.txt\"):\n","   # keep track of the number of words\n","    lexiconsize = 0\n","   # initialize an empty dictionary\n","    word_dict = {}\n","   # create a feature for unknown words\n","    word_dict[\"@unk\"] = lexiconsize\n","    lexiconsize += 1\n","   # read in the vocabular file\n","    with open(vocab_path, \"r\") as f:\n","        data = f.readlines()\n","   # Process the file a line at a time.\n","    for line in data:\n","        # The count is the first 3 characters\n","        count = int(line[0:4])\n","        # The word is the rest of the string\n","        token = line[5:-1]\n","       # Create a feature if it’s appeared at least twice\n","        if count > 1: \n","            word_dict[token] = lexiconsize\n","            lexiconsize += 1\n","    # squirrel away the total size for later reference\n","    word_dict[\"@size\"] = lexiconsize\n","    return(word_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtrIFcpdlfL4","colab_type":"text"},"source":["We will download the vocabulary data from GitHub, `vocab.txt`"]},{"cell_type":"code","metadata":{"id":"_4zEAMdFlV4i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1593963799564,"user_tz":240,"elapsed":3339,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"31e04b94-de52-4644-feea-d0eeb170bbc0"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/vocab.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-05 15:43:17--  https://github.com/mlittmancs/great_courses_ml/raw/master/vocab.txt\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab.txt [following]\n","--2020-07-05 15:43:18--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/vocab.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 83233 (81K) [text/plain]\n","Saving to: ‘vocab.txt.1’\n","\n","vocab.txt.1         100%[===================>]  81.28K  --.-KB/s    in 0.03s   \n","\n","2020-07-05 15:43:18 (2.70 MB/s) - ‘vocab.txt.1’ saved [83233/83233]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3bfuoWdmlnWx","colab_type":"text"},"source":["Next, we write a `tokenize` function to turn each word into a list of the length of the number words.  Every item in the list is a count of the number of times a given word occurs in the list."]},{"cell_type":"code","metadata":{"id":"tRAc__I-lV7i","colab_type":"code","colab":{}},"source":["# Turn string str into a vector.\n","def tokenize(email_string, word_dict):\n","  # initially the vector is all zeros\n","  vec = [0 for i in range(word_dict[\"@size\"])]\n","  # for each word\n","  for t in email_string.split(\" \"):\n","   # if the word has a feature, add one to the corresponding feature\n","    if t in word_dict: vec[word_dict[t]] += 1\n","   # otherwise, count it as an unk\n","    else: vec[word_dict[\"@unk\"]] += 1\n","  return(vec)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gh-7PbXblsei","colab_type":"text"},"source":["From here, we write a `getdat` function to convert the file we downloaded into two lists:\n","\n","- `dat`: a list of lists of tokenized words\n","- `labs`: a list of labels associated with the email being spam or not spam"]},{"cell_type":"code","metadata":{"id":"y6nWYYX-lV-I","colab_type":"code","colab":{}},"source":["# read in labeled examples and turn the strings into vectors\n","def getdat(filename, word_dict):\n","    with open(filename, \"r\") as f:\n","        data = f.readlines()\n","    dat = []\n","    labs = []\n","    for line in data:\n","        labs = labs + [int(line[0])]\n","        dat = dat + [tokenize(line[2:], word_dict)]\n","    return(dat, labs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCy39occlyhW","colab_type":"text"},"source":["Now we'll download the train and test data from GitHub"]},{"cell_type":"code","metadata":{"id":"uezgvCpNlWEC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1593963811849,"user_tz":240,"elapsed":6158,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"7df416de-0574-4d08-af7f-1bff95f3ed57"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/spam-test.csv\n","!wget https://github.com/mlittmancs/great_courses_ml/raw/master/spam-train.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-05 15:43:27--  https://github.com/mlittmancs/great_courses_ml/raw/master/spam-test.csv\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/spam-test.csv [following]\n","--2020-07-05 15:43:27--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/spam-test.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 166047 (162K) [text/plain]\n","Saving to: ‘spam-test.csv.1’\n","\n","spam-test.csv.1     100%[===================>] 162.16K  --.-KB/s    in 0.04s   \n","\n","2020-07-05 15:43:28 (3.77 MB/s) - ‘spam-test.csv.1’ saved [166047/166047]\n","\n","--2020-07-05 15:43:29--  https://github.com/mlittmancs/great_courses_ml/raw/master/spam-train.csv\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/spam-train.csv [following]\n","--2020-07-05 15:43:30--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/spam-train.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 289027 (282K) [text/plain]\n","Saving to: ‘spam-train.csv.1’\n","\n","spam-train.csv.1    100%[===================>] 282.25K  --.-KB/s    in 0.06s   \n","\n","2020-07-05 15:43:30 (4.65 MB/s) - ‘spam-train.csv.1’ saved [289027/289027]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IhMmVtWUl6xr","colab_type":"text"},"source":["With these train and test datasets, we'll build create the data and labels we will use to train and use to test our naive Bayes model."]},{"cell_type":"code","metadata":{"id":"N4gjdq5flz66","colab_type":"code","colab":{}},"source":["word_dict = readvocab()\n","traindat, trainlabs = getdat(\"spam-train.csv\", word_dict)\n","testdat, testlabs = getdat(\"spam-test.csv\", word_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK2zz8sNvfUQ","colab_type":"text"},"source":["Now we'll use IBM's `diffprivlib` to train differentially private models."]},{"cell_type":"code","metadata":{"id":"5nrRpeNpsoxv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"executionInfo":{"status":"ok","timestamp":1593964202508,"user_tz":240,"elapsed":6777,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"125fca3a-7b55-4de3-f3d1-88de33da8497"},"source":["!pip install diffprivlib"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting diffprivlib\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/b8/852409057d6acc060f06cac8d0a45b73dfa54ee4fbd1577c9a7d755e9fb6/diffprivlib-0.3.0.tar.gz (70kB)\n","\r\u001b[K     |████▋                           | 10kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.18.5)\n","Requirement already satisfied: setuptools>=39.0.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (47.3.1)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.22.2.post1)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from diffprivlib) (0.15.1)\n","Building wheels for collected packages: diffprivlib\n","  Building wheel for diffprivlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffprivlib: filename=diffprivlib-0.3.0-cp36-none-any.whl size=138998 sha256=d36d89c673ce76aaffb5fe65ccc3481aea9240df0d8bb3e352e3d3a4e3caf216\n","  Stored in directory: /root/.cache/pip/wheels/64/68/62/617183f73d3feceab2c9d4081714a27bc11be5bb3f10f59b8a\n","Successfully built diffprivlib\n","Installing collected packages: diffprivlib\n","Successfully installed diffprivlib-0.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F5Ks-cGAroOs","colab_type":"text"},"source":["SciKit Learn's `GaussianNB`"]},{"cell_type":"code","metadata":{"id":"baShUQ4AqrZK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593967237699,"user_tz":240,"elapsed":2518,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"2ce2a9c7-7c53-4ce5-c220-913ff2aaed1c"},"source":["from sklearn.naive_bayes import GaussianNB\n","\n","gnb = GaussianNB()\n","\n","gnb = MultinomialNB()\n","gnb.fit(traindat, trainlabs)\n","score = gnb.score(testdat, testlabs)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.985\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pkIXxwtHrwS_","colab_type":"text"},"source":["Diff Priv Lab's `GaussianNB`"]},{"cell_type":"code","metadata":{"id":"qbD3D61vqre_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593967234930,"user_tz":240,"elapsed":2127,"user":{"displayName":"Michael Littman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1OI1zp1NevMSZ87UN47k8bTZ--Ijr4v3ORV33Vg=s64","userId":"06751891446459829367"}},"outputId":"7b5572e9-80cd-4844-b67f-f150afe3c904"},"source":["from diffprivlib.models import GaussianNB\n","\n","gnb = GaussianNB()\n","\n","gnb = MultinomialNB()\n","gnb.fit(traindat, trainlabs)\n","score = gnb.score(testdat, testlabs)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.985\n"],"name":"stdout"}]}]}
