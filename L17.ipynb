{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L17.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eDEziJFNRShb","colab_type":"text"},"source":["Let’s write some python code to use all four of the released models for generating text. That will let us see how the changes in capacity related to the quality of the text produced.\n","\n","We download the GPT-2 library from OpenAI.\n","\n","The OpenAI codebase has a list of other libraries that it requires, which is handled by installing requirements.txt. We go to the appropriate file, requirements.txt, and install those libraries.\n","\n","Then, we download four different pre-trained models OpenAI made available, each roughly double in size from the previous."]},{"cell_type":"code","metadata":{"id":"bHr2nt3-ktjE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590504981818,"user_tz":240,"elapsed":267591,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"edb86d7e-de62-4650-e598-2732c87dab91"},"source":["!git clone https://github.com/openai/gpt-2.git\n","import os\n","os.chdir(\"gpt-2\")\n","import warnings\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","warnings.filterwarnings('ignore')\n","%tensorflow_version 1.x\n","!pip3 install -r requirements.txt\n","!python3 download_model.py 124M\n","!python3 download_model.py 345M\n","!python3 download_model.py 774M\n","!python3 download_model.py 1558M"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'gpt-2' already exists and is not an empty directory.\n","TensorFlow 1.x selected.\n","Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.3.1)\n","Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n","Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n","Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n","Fetching checkpoint: 1.00kit [00:00, 808kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 36.3Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 804kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 498Mit [00:09, 52.5Mit/s]                                  \n","Fetching model.ckpt.index: 6.00kit [00:00, 5.35Mit/s]                                               \n","Fetching model.ckpt.meta: 472kit [00:00, 32.3Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 34.4Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 771kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 39.0Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 1.04Mit/s]                                                   \n","Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:29, 47.8Mit/s]                                 \n","Fetching model.ckpt.index: 11.0kit [00:00, 6.88Mit/s]                                               \n","Fetching model.ckpt.meta: 927kit [00:00, 33.0Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 30.7Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 730kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 38.5Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 722kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:13, 42.0Mit/s]                                 \n","Fetching model.ckpt.index: 16.0kit [00:00, 10.7Mit/s]                                               \n","Fetching model.ckpt.meta: 1.38Mit [00:00, 41.2Mit/s]                                                \n","Fetching vocab.bpe: 457kit [00:00, 29.7Mit/s]                                                       \n","Fetching checkpoint: 1.00kit [00:00, 679kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 32.8Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 640kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:21, 44.0Mit/s]                                 \n","Fetching model.ckpt.index: 21.0kit [00:00, 11.6Mit/s]                                               \n","Fetching model.ckpt.meta: 1.84Mit [00:00, 35.2Mit/s]                                                \n","Fetching vocab.bpe: 457kit [00:00, 28.5Mit/s]                                                       \n","Cloning into 'gpt-2'...\n","remote: Enumerating objects: 230, done.\u001b[K\n","remote: Total 230 (delta 0), reused 0 (delta 0), pack-reused 230\u001b[K\n","Receiving objects: 100% (230/230), 4.38 MiB | 3.38 MiB/s, done.\n","Resolving deltas: 100% (119/119), done.\n","Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.3.1)\n","Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n","Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n","Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n","Fetching checkpoint: 1.00kit [00:00, 928kit/s]                                                      \n","Fetching encoder.json: 1.04Mit [00:00, 38.6Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 701kit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001:  18%|██▉              | 87.3M/498M [00:01<00:07, 57.6Mit/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N2ulVIo6RWv_","colab_type":"text"},"source":["Next we import some addtional libraries we'll be using in this notebook."]},{"cell_type":"code","metadata":{"id":"w3wQ28G3lJVT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1590504994599,"user_tz":240,"elapsed":280366,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"3d286edc-033e-48ad-b64f-e72c3bae5ea9"},"source":["!export PYTHONIOENCODING=UTF-8\n","os.chdir('src')\n","\n","!pip install tensorflow=='1.15.2'\n","import model, sample, encoder\n","import json\n","import numpy as np\n","import tensorflow as tf"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.15.2 in /tensorflow-1.15.2/python3.6 (1.15.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.29.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow==1.15.2) (1.15.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2b749963aa9409cdb84d20c357f6890fa518f8ef9c9428e7b57605ee64dd9d01\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","Installing collected packages: gast\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed gast-0.2.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MTFrok1ARZyz","colab_type":"text"},"source":["We define an `autocomplete` function that returns the next `length` number of words given the `model_name` and the `raw_text` input.\n","\n","We set up a session for talking to the tensorflow backend. We also create a place for the output of the model to go. We checkpoint the tensorflow backend so we can establish the link to our code.Once all of that is set up, we can send our text prompt to the model for processing. We pull out the output of the model and return the string."]},{"cell_type":"code","metadata":{"id":"Uckub33ZlOTR","colab_type":"code","colab":{}},"source":["# Return-a-string version\n","\n","def autocomplete(model_name, raw_text, length):\n","    batch_size = 1\n","    temperature = 1\n","    top_k = 0\n","    models_dir = '../models'\n","    seed = None\n","    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n","\n","    enc = encoder.get_encoder(model_name, models_dir)\n","    hparams = model.default_hparams()\n","    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n","        hparams.override_from_dict(json.load(f))\n","\n","    if length > hparams.n_ctx:\n","        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n","\n","    with tf.Session(graph=tf.Graph()) as sess:\n","        context = tf.placeholder(tf.int32, [batch_size, None])\n","        np.random.seed(seed)\n","        tf.set_random_seed(seed)\n","        output = sample.sample_sequence(\n","            hparams=hparams, length=length,\n","            context=context,\n","            batch_size=batch_size,\n","            temperature=temperature, top_k=top_k\n","        )\n","\n","        saver = tf.train.Saver()\n","        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n","        saver.restore(sess, ckpt)\n","\n","        context_tokens = enc.encode(raw_text)\n","        out = sess.run(output, feed_dict={\n","                context: [context_tokens]\n","        })[:, len(context_tokens):]\n","        text = enc.decode(out[0])\n","    return(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUrae7LcRd3z","colab_type":"text"},"source":["Below is an example of our `autocomplete` function, printing out the next 10 predicted words."]},{"cell_type":"code","metadata":{"id":"olLMrz6plc1n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"status":"ok","timestamp":1590505012547,"user_tz":240,"elapsed":298303,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"c7a8cb32-fa73-4969-caa4-14fc007af812"},"source":["print(autocomplete('124M', \"Learning about machine learning is kind of like\", 10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n","\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n"," yesterday controlling an electric car in the 1970s.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZPKhoX45Rin_","colab_type":"text"},"source":["Here show how the predictions for a given phrase changes with the number of parameters in the model."]},{"cell_type":"code","metadata":{"id":"GGeP35JUlb6N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1590505323998,"user_tz":240,"elapsed":609745,"user":{"displayName":"JZ Forde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiwSogjDlg0BxeyyCUFJ3t-a6Mt210NSXjrBuLMYw=s64","userId":"11263008094098858557"}},"outputId":"9d87f038-e00d-4556-b679-134af3ef9d13"},"source":["for gpt2model in ['124M', '345M', '774M', '1558M']:\n","  print(gpt2model, autocomplete(gpt2model, \"My first time visiting the ocean, I marveled at\", 20))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ../models/124M/model.ckpt\n","124M  it on a daily basis. The ocean is surrounded by fog, and you have fog gods; they\n","INFO:tensorflow:Restoring parameters from ../models/345M/model.ckpt\n","345M  many astonishing colors — reds with rings of orange, magenta with gold, little green gray sites\n","INFO:tensorflow:Restoring parameters from ../models/774M/model.ckpt\n","774M  it under my umbrella.\n","\n","Compared to living in Japan, Italy is essentially the smallest nation in\n","INFO:tensorflow:Restoring parameters from ../models/1558M/model.ckpt\n","1558M  it in awe of the overwhelming force of the water. But I was so shy about revealing myself to\n"],"name":"stdout"}]}]}
